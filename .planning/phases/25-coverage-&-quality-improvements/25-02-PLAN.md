---
phase: 25-coverage-quality
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - pkg/driver/node_test.go
  - pkg/mount/mount_test.go
autonomous: true

must_haves:
  truths:
    - "NVMe connection failures return codes.Internal with actionable message"
    - "Mount failures return codes.Internal with device path"
    - "Device path resolution failures are handled gracefully"
    - "Stale mount scenarios have test coverage"
  artifacts:
    - path: "pkg/driver/node_test.go"
      provides: "Node error path tests"
      contains: "TestNodeStageVolume_ErrorScenarios"
    - path: "pkg/mount/mount_test.go"
      provides: "Mount error path tests"
      contains: "TestMount_ErrorScenarios"
  key_links:
    - from: "pkg/driver/node.go"
      to: "pkg/nvme"
      via: "NVMe connection error handling"
      pattern: "nvmeConn\\.(Connect|Disconnect)"
    - from: "pkg/driver/node.go"
      to: "pkg/mount"
      via: "Mount error handling"
      pattern: "mounter\\.(Mount|Unmount|Format)"
---

<objective>
Add comprehensive error path test coverage for node service NVMe connection failures, mount failures, and device path changes.

Purpose: COV-02 requires error paths in node service have test coverage for NVMe connection failures, mount failures, and device path changes. Current pkg/driver coverage is 50.8% and pkg/mount is 68.4% - node service error paths need focused testing.

Output: Table-driven error path tests validating node service handles infrastructure failures correctly.
</objective>

<execution_context>
@/Users/whiskey/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whiskey/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/25-coverage-&-quality-improvements/25-RESEARCH.md

@pkg/driver/node.go
@pkg/driver/node_test.go
@pkg/mount/mount.go
@pkg/mount/mount_test.go
@pkg/nvme/nvme.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add NodeStageVolume error path tests</name>
  <files>pkg/driver/node_test.go</files>
  <action>
Add `TestNodeStageVolume_ErrorScenarios` table-driven tests covering:

1. **NVMe Connection Timeout** - Target unreachable
   - Setup: `mockNVME.connectErr = errors.New("nvme: connection timeout")`
   - Expected: `codes.Internal` with message mentioning "NVMe" and "connect"

2. **NVMe Connection Refused** - Wrong port/address
   - Setup: `mockNVME.connectErr = errors.New("connection refused")`
   - Expected: `codes.Internal` with actionable error

3. **Device Not Found After Connect** - Device path empty
   - Setup: Connect succeeds but `devicePath = ""`
   - Expected: `codes.Internal` with message about device not appearing

4. **Format Failure** - Filesystem format fails (for filesystem volumes)
   - Setup: `mockMounter.formatErr = errors.New("mkfs failed")`
   - Expected: `codes.Internal` with format error

5. **Mount Failure** - Mount syscall fails
   - Setup: `mockMounter.mountErr = errors.New("mount: permission denied")`
   - Expected: `codes.Internal` with mount error

6. **Missing Required Context** - NQN not provided
   - Setup: Request without `nqn` in VolumeContext
   - Expected: `codes.InvalidArgument`

7. **Invalid NQN Format** - Malformed NQN
   - Setup: `VolumeContext["nqn"] = "not-a-valid-nqn"`
   - Expected: `codes.InvalidArgument`

Use existing mock types from node_test.go (mockMounter, mockNVMEConnector). Extend mocks if needed.

Test structure:
```go
func TestNodeStageVolume_ErrorScenarios(t *testing.T) {
    tests := []struct {
        name      string
        setupMock func(*mockNVMEConnector, *mockMounter)
        request   *csi.NodeStageVolumeRequest
        expectErr bool
        errCode   codes.Code
        errMsg    string
    }{
        // test cases...
    }

    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            // setup and run
        })
    }
}
```
  </action>
  <verify>
Run `go test -v -run TestNodeStageVolume_ErrorScenarios ./pkg/driver/...` - all 7 error scenarios pass with correct codes.
  </verify>
  <done>
NodeStageVolume has 7+ error scenarios tested with verified gRPC error codes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add NodeUnstageVolume error path tests</name>
  <files>pkg/driver/node_test.go</files>
  <action>
Add `TestNodeUnstageVolume_ErrorScenarios` table-driven tests covering:

1. **Unmount Failure** - Filesystem busy
   - Setup: `mockMounter.unmountErr = errors.New("target is busy")`
   - Expected: `codes.Internal` with retry guidance

2. **NVMe Disconnect Failure** - Connection stuck
   - Setup: `mockNVME.disconnectErr = errors.New("disconnect timeout")`
   - Expected: `codes.Internal` (but operation should be idempotent-safe)

3. **Staging Path Not Found** - Already cleaned up
   - Setup: Non-existent staging path
   - Expected: Success (idempotent)

4. **Partial Cleanup State** - Unmounted but not disconnected
   - Setup: Staging dir exists but not mounted
   - Expected: Disconnect still attempted, success

5. **Invalid Volume ID** - Empty or malformed
   - Setup: `VolumeId = ""`
   - Expected: `codes.InvalidArgument`

Idempotency is critical for NodeUnstageVolume - Kubernetes may retry multiple times during pod deletion.
  </action>
  <verify>
Run `go test -v -run TestNodeUnstageVolume_ErrorScenarios ./pkg/driver/...` - all cases pass.
  </verify>
  <done>
NodeUnstageVolume has 5+ error scenarios tested including idempotency behavior.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add mount package error path tests</name>
  <files>pkg/mount/mount_test.go</files>
  <action>
Add `TestMount_ErrorScenarios` and `TestStaleMount_ErrorScenarios` to improve pkg/mount coverage from 68.4% to 70%+.

**Mount error scenarios:**
1. **Mount Target Exists as File** - Target path is a file, not directory
2. **Device Not Formatted** - Raw device without filesystem
3. **Read-Only Filesystem** - Mount with RO flag handling
4. **Invalid Mount Options** - Unsupported options

**Stale mount scenarios:**
1. **Mount Point Not in /proc/mounts** - StaleReasonMountNotFound
2. **Device Disappeared** - StaleReasonDeviceDisappeared
3. **Device Mismatch** - Different device than expected (StaleReasonDeviceMismatch)
4. **Healthy Mount** - All checks pass

Focus on error paths that have low coverage. Check current coverage:
```bash
go test -covermode=atomic -coverprofile=/tmp/mount-cov.out ./pkg/mount/...
go tool cover -func=/tmp/mount-cov.out
```

Target functions with <70% coverage for new tests.
  </action>
  <verify>
Run `go test -v -race -coverprofile=/tmp/mount-cov.out ./pkg/mount/...` and check `go tool cover -func=/tmp/mount-cov.out | grep total` shows >= 70%.
  </verify>
  <done>
pkg/mount coverage reaches target 70% with error path and stale mount scenarios tested.
  </done>
</task>

</tasks>

<verification>
```bash
# Run all node tests with race detection
go test -v -race ./pkg/driver/... -run "Node"

# Run mount tests
go test -v -race ./pkg/mount/...

# Check overall coverage improvement
go test -covermode=atomic -coverprofile=/tmp/cov.out ./pkg/driver/... ./pkg/mount/...
go tool cover -func=/tmp/cov.out | grep -E "(driver|mount)"
```

Expected: Node service error paths covered, mount package at 70%+.
</verification>

<success_criteria>
1. TestNodeStageVolume_ErrorScenarios exists with 7+ error cases
2. TestNodeUnstageVolume_ErrorScenarios exists with 5+ error cases
3. TestMount_ErrorScenarios exists with 4+ cases
4. TestStaleMount_ErrorScenarios exists with 4+ cases
5. All tests pass with -race flag
6. pkg/mount coverage >= 70%
7. Error messages are actionable (include device path, NQN where relevant)
</success_criteria>

<output>
After completion, create `.planning/phases/25-coverage-&-quality-improvements/25-02-SUMMARY.md`
</output>
