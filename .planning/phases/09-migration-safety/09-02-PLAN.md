---
phase: 09-migration-safety
plan: 02
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - pkg/driver/controller.go
autonomous: true

must_haves:
  truths:
    - "Migration timeout checked before allowing secondary attachment"
    - "Non-migration RWO dual-attach fails immediately (no grace period abuse)"
    - "Timed-out migration rejects new attachments with clear error message"
    - "RWO conflict detection distinct from RWX migration timeout"
  artifacts:
    - path: "pkg/driver/controller.go"
      provides: "Migration-aware ControllerPublishVolume logic"
      contains: "IsMigrationTimedOut"
  key_links:
    - from: "pkg/driver/controller.go"
      to: "pkg/attachment/types.go"
      via: "IsMigrationTimedOut check"
      pattern: "IsMigrationTimedOut\\(\\)"
    - from: "pkg/driver/controller.go"
      to: "pkg/driver/params.go"
      via: "ParseMigrationTimeout call"
      pattern: "ParseMigrationTimeout"
---

<objective>
Implement migration timeout enforcement in ControllerPublishVolume, separating it from RWO grace period logic

Purpose: SAFETY-01 and SAFETY-02 - Migration timeout allows expected dual-attach window while non-migration conflicts fail immediately
Output: ControllerPublishVolume checks migration timeout before allowing secondary attachment, rejects timed-out migrations
</objective>

<execution_context>
@/Users/whiskey/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whiskey/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/milestones/v0.5-ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-migration-safety/09-RESEARCH.md
@.planning/phases/09-migration-safety/09-01-PLAN.md

# Key existing code
@pkg/driver/controller.go
@pkg/attachment/types.go
@pkg/attachment/manager.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add migration timeout check in RWX secondary attachment flow</name>
  <files>pkg/driver/controller.go</files>
  <action>
Update ControllerPublishVolume to check migration timeout BEFORE allowing secondary attachment.

In the RWX branch where secondary attachment is allowed (after checking nodeCount < 2), add migration timeout check:

```go
        if isRWX {
            // RWX: Allow second attachment if within limit
            nodeCount := am.GetNodeCount(volumeID)
            if nodeCount >= 2 {
                // ROADMAP-5: 2-node migration limit reached
                klog.Warningf("RWX volume %s already attached to 2 nodes, rejecting 3rd attachment to %s",
                    volumeID, nodeID)
                return nil, status.Errorf(codes.FailedPrecondition,
                    "Volume %s already attached to 2 nodes (migration limit). Wait for migration to complete. Attached nodes: %v",
                    volumeID, existing.GetNodeIDs())
            }

            // SAFETY-01: Check if existing migration has timed out
            // This prevents indefinite dual-attach if migration fails
            if existing.IsMigrationTimedOut() {
                elapsed := time.Since(*existing.MigrationStartedAt)
                klog.Warningf("RWX volume %s migration timed out (%v elapsed, %v max), rejecting new secondary attachment",
                    volumeID, elapsed, existing.MigrationTimeout)
                return nil, status.Errorf(codes.FailedPrecondition,
                    "Volume %s migration timeout exceeded (%v elapsed, %v max). "+
                    "Previous migration may be stuck. Detach source node to reset, or adjust migrationTimeoutSeconds in StorageClass.",
                    volumeID, elapsed.Round(time.Second), existing.MigrationTimeout)
            }

            // Parse migration timeout from volume context (passed from CreateVolume)
            migrationTimeout := ParseMigrationTimeout(req.GetVolumeContext())

            // Allow second attachment for migration
            klog.V(2).Infof("Allowing second attachment of RWX volume %s to node %s (migration target, timeout=%v)",
                volumeID, nodeID, migrationTimeout)
            if err := am.AddSecondaryAttachment(ctx, volumeID, nodeID, migrationTimeout); err != nil {
                return nil, status.Errorf(codes.Internal, "failed to track secondary attachment: %v", err)
            }

            // ... rest of existing code
        }
```

Note: The migration timeout is parsed from VolumeContext which contains the StorageClass parameters that were stored during CreateVolume.
  </action>
  <verify>grep -n "IsMigrationTimedOut" pkg/driver/controller.go shows the timeout check</verify>
  <done>ControllerPublishVolume checks migration timeout before allowing secondary RWX attachment</done>
</task>

<task type="auto">
  <name>Task 2: Ensure RWO conflicts fail immediately (no grace period abuse for RWX-like behavior)</name>
  <files>pkg/driver/controller.go</files>
  <action>
Verify and document that the RWO path does NOT use grace period to allow dual-attach. The grace period is ONLY for reattachment after detach, not for concurrent attachment.

Add a clarifying comment in the RWO conflict section:

```go
        } else {
            // RWO: Fail immediately for dual-attach attempts
            // SAFETY-02: Grace period is ONLY for reattachment AFTER detach
            // It does NOT allow concurrent multi-node attachment like RWX
            // This distinction is critical: grace period tolerates network blips during
            // pod migration where old pod dies before new pod starts. It does NOT
            // enable live migration where both nodes need simultaneous access.

            gracePeriod := cs.driver.GetAttachmentGracePeriod()
            if gracePeriod > 0 && am.IsWithinGracePeriod(volumeID, gracePeriod) {
                // ... existing grace period handling for REATTACHMENT
            }
            // ... rest of existing RWO conflict handling
        }
```

This task is primarily documentation and verification - the existing code already has correct behavior. The key is to ensure the grace period only applies to the detach-then-reattach flow, not to concurrent attachment.

Verify the existing flow:
1. RWO volume attached to Node A
2. Pod moves to Node B - kubelet calls ControllerUnpublishVolume (detaches from A)
3. Detach timestamp recorded
4. ControllerPublishVolume called for Node B
5. Grace period check: "was volume recently detached?" - yes, allow attachment
6. This is SEQUENTIAL (A detaches, THEN B attaches), not CONCURRENT

The current implementation is correct. Add the clarifying comment to prevent future confusion.
  </action>
  <verify>grep -A5 "SAFETY-02" pkg/driver/controller.go shows the clarifying comment</verify>
  <done>RWO path documented to clarify grace period is for reattachment, not concurrent attachment</done>
</task>

<task type="auto">
  <name>Task 3: Add migration timeout parameter to CreateVolume response</name>
  <files>pkg/driver/controller.go</files>
  <action>
Update CreateVolume to include the migrationTimeoutSeconds in the VolumeContext so it's available to ControllerPublishVolume.

In CreateVolume, after parsing NVMe connection parameters:

```go
    // Parse migration timeout from StorageClass for later use in ControllerPublishVolume
    migrationTimeout := ParseMigrationTimeout(params)

    // ... existing volume creation code ...

    // Return volume information with migration timeout in context
    return &csi.CreateVolumeResponse{
        Volume: &csi.Volume{
            VolumeId:      volumeID,
            CapacityBytes: requiredBytes,
            VolumeContext: map[string]string{
                "rdsAddress":              cs.getRDSAddress(params),
                "nvmeAddress":             cs.getNVMEAddress(params),
                "nvmePort":                fmt.Sprintf("%d", nvmePort),
                "nqn":                     nqn,
                "volumePath":              filePath,
                "ctrlLossTmo":             fmt.Sprintf("%d", nvmeParams.CtrlLossTmo),
                "reconnectDelay":          fmt.Sprintf("%d", nvmeParams.ReconnectDelay),
                "keepAliveTmo":            fmt.Sprintf("%d", nvmeParams.KeepAliveTmo),
                "migrationTimeoutSeconds": fmt.Sprintf("%d", int(migrationTimeout.Seconds())),
            },
        },
    }, nil
```

Also update the existing volume response (idempotent case) to include migrationTimeoutSeconds.

This ensures the timeout configured in StorageClass is preserved and available during ControllerPublishVolume even though the original parameters are not directly available there.
  </action>
  <verify>grep -n "migrationTimeoutSeconds" pkg/driver/controller.go shows it in CreateVolume response</verify>
  <done>CreateVolume includes migrationTimeoutSeconds in VolumeContext for ControllerPublishVolume to use</done>
</task>

</tasks>

<verification>
1. `go build ./...` - code compiles
2. `make test` - existing tests pass
3. Verify migration timeout check: grep "IsMigrationTimedOut" pkg/driver/controller.go
4. Verify migrationTimeoutSeconds in VolumeContext: grep "migrationTimeoutSeconds" pkg/driver/controller.go
5. Verify SAFETY-02 comment: grep "SAFETY-02" pkg/driver/controller.go
</verification>

<success_criteria>
- ControllerPublishVolume checks IsMigrationTimedOut() before allowing secondary RWX attachment
- Timed-out migrations rejected with clear error message including elapsed time and max timeout
- RWO path has clarifying comment explaining grace period vs concurrent attachment distinction
- CreateVolume includes migrationTimeoutSeconds in VolumeContext
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/09-migration-safety/09-02-SUMMARY.md`
</output>
