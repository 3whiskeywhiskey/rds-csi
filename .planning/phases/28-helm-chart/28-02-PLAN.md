---
phase: 28-helm-chart
plan: 02
type: execute
wave: 2
depends_on: ["28-01"]
files_modified:
  - deploy/helm/rds-csi-driver/templates/namespace.yaml
  - deploy/helm/rds-csi-driver/templates/serviceaccount.yaml
  - deploy/helm/rds-csi-driver/templates/rbac.yaml
  - deploy/helm/rds-csi-driver/templates/csidriver.yaml
  - deploy/helm/rds-csi-driver/templates/controller.yaml
  - deploy/helm/rds-csi-driver/templates/node.yaml
autonomous: true

must_haves:
  truths:
    - "Controller Deployment template renders with all 6 containers (driver + 5 sidecars) using values from values.yaml"
    - "Node DaemonSet template renders with 3 containers (driver + registrar + livenessprobe) using values from values.yaml"
    - "RBAC template creates controller and node ServiceAccounts, ClusterRoles, and ClusterRoleBindings with templated namespace"
    - "CSIDriver resource uses hardcoded driver name rds.csi.srvlab.io with all existing spec fields preserved"
    - "All templates use {{ .Release.Namespace }} instead of hardcoded namespace"
    - "All sidecar leader-election-namespace args use {{ .Release.Namespace }}"
    - "Controller template mounts Secret at /etc/rds-csi with key paths rds-private-key and rds-host-key matching deployed manifests"
    - "helm template generates valid YAML for all core resources"
  artifacts:
    - path: "deploy/helm/rds-csi-driver/templates/controller.yaml"
      provides: "Controller Deployment with driver + 5 sidecars"
      contains: "kind: Deployment"
    - path: "deploy/helm/rds-csi-driver/templates/node.yaml"
      provides: "Node DaemonSet with driver + registrar + livenessprobe"
      contains: "kind: DaemonSet"
    - path: "deploy/helm/rds-csi-driver/templates/rbac.yaml"
      provides: "RBAC resources for controller and node"
      contains: "kind: ClusterRole"
    - path: "deploy/helm/rds-csi-driver/templates/csidriver.yaml"
      provides: "CSIDriver resource registration"
      contains: "kind: CSIDriver"
    - path: "deploy/helm/rds-csi-driver/templates/serviceaccount.yaml"
      provides: "ServiceAccount resources"
      contains: "kind: ServiceAccount"
  key_links:
    - from: "deploy/helm/rds-csi-driver/templates/controller.yaml"
      to: "deploy/helm/rds-csi-driver/templates/_helpers.tpl"
      via: "include rds-csi.labels and rds-csi.selectorLabels"
      pattern: "include.*rds-csi\\.labels"
    - from: "deploy/helm/rds-csi-driver/templates/rbac.yaml"
      to: "deploy/helm/rds-csi-driver/templates/serviceaccount.yaml"
      via: "ClusterRoleBinding subjects reference ServiceAccount name"
      pattern: "serviceAccountName.*rds-csi"
    - from: "deploy/helm/rds-csi-driver/templates/controller.yaml"
      to: "deploy/helm/rds-csi-driver/values.yaml"
      via: "all container args templated from .Values.rds and .Values.controller"
      pattern: "\\.Values\\.rds\\."
    - from: "deploy/helm/rds-csi-driver/templates/controller.yaml"
      to: "rds.secretName"
      via: "Secret volume references .Values.rds.secretName for credential mounting"
      pattern: "secretName.*\\.Values\\.rds\\.secretName"
---

<objective>
Create the core Helm templates for the CSI driver infrastructure: controller Deployment, node DaemonSet, RBAC, CSIDriver, ServiceAccount, and namespace resources.

Purpose: These templates convert the existing hardcoded Kubernetes manifests into configurable Helm templates. They are the functional core of the chart -- without them, nothing deploys.

Output: Six template files that produce equivalent resources to deploy/kubernetes/ manifests when rendered with default values, but fully configurable via values.yaml overrides.
</objective>

<execution_context>
@/Users/whiskey/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whiskey/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-helm-chart/28-CONTEXT.md
@.planning/phases/28-helm-chart/28-RESEARCH.md
@deploy/kubernetes/controller.yaml
@deploy/kubernetes/node.yaml
@deploy/kubernetes/rbac.yaml
@deploy/kubernetes/csidriver.yaml
@deploy/kubernetes/namespace.yaml
@deploy/helm/rds-csi-driver/Chart.yaml
@deploy/helm/rds-csi-driver/values.yaml
@deploy/helm/rds-csi-driver/templates/_helpers.tpl
@cmd/rds-csi-plugin/main.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create namespace, serviceaccount, rbac, and csidriver templates</name>
  <files>
    deploy/helm/rds-csi-driver/templates/namespace.yaml
    deploy/helm/rds-csi-driver/templates/serviceaccount.yaml
    deploy/helm/rds-csi-driver/templates/rbac.yaml
    deploy/helm/rds-csi-driver/templates/csidriver.yaml
  </files>
  <action>
**namespace.yaml** - Conditional namespace creation:
```
{{- if .Values.namespace.create }}
apiVersion: v1
kind: Namespace
metadata:
  name: {{ .Release.Namespace }}
  labels:
    {{- include "rds-csi.labels" . | nindent 4 }}
{{- end }}
```

**serviceaccount.yaml** - Two ServiceAccounts (controller + node):
- Controller: `{{ include "rds-csi.fullname" . }}-controller` in `{{ .Release.Namespace }}`
- Node: `{{ include "rds-csi.fullname" . }}-node` in `{{ .Release.Namespace }}`
- Both get standard labels from `include "rds-csi.labels"`

**rbac.yaml** - Convert from deploy/kubernetes/rbac.yaml preserving ALL existing rules exactly:
- Controller ClusterRole: `{{ include "rds-csi.fullname" . }}-controller-role` with ALL existing rules (PVs, PVCs, PVC status, StorageClasses, VolumeAttachments, VolumeAttachment status, CSINodes, Nodes, Events, Leases, CSIDrivers, snapshot.storage.k8s.io resources). Copy rules VERBATIM from the existing rbac.yaml -- do not omit or modify any rule.
- Node ClusterRole: `{{ include "rds-csi.fullname" . }}-node-role` with existing rules (CSINodes, Nodes, Events)
- Controller ClusterRoleBinding: subjects namespace = `{{ .Release.Namespace }}`
- Node ClusterRoleBinding: subjects namespace = `{{ .Release.Namespace }}`
- All resources get standard labels from helpers

**csidriver.yaml** - The CSIDriver name MUST remain `rds.csi.srvlab.io` (hardcoded, not templated from chart name -- this is the CSI driver registration name):
```
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: rds.csi.srvlab.io
  labels:
    {{- include "rds-csi.labels" . | nindent 4 }}
spec:
  attachRequired: true
  podInfoOnMount: true
  volumeLifecycleModes:
    - Persistent
  fsGroupPolicy: File
  requiresRepublish: false
  storageCapacity: true
  tokenRequests: []
```
Preserve ALL spec fields exactly from deploy/kubernetes/csidriver.yaml.

CRITICAL: Never use `{{ .Release.Namespace }}` in ClusterRole or ClusterRoleBinding metadata (they are cluster-scoped). Only use it in subjects and ServiceAccount metadata.
  </action>
  <verify>
Run `helm template test-release deploy/helm/rds-csi-driver/ --namespace rds-csi` and verify:
1. ServiceAccounts exist with correct names and namespace
2. ClusterRoles have all RBAC rules from the original manifests
3. ClusterRoleBindings reference correct namespace in subjects
4. CSIDriver name is `rds.csi.srvlab.io` (not templated)

**RBAC rule verification (REQUIRED):** Extract and diff the controller ClusterRole rules between the rendered Helm template and the existing manifest to confirm no rules were dropped or modified:
```bash
# Extract controller ClusterRole rules from existing manifest
yq '.rules' deploy/kubernetes/rbac.yaml > /tmp/existing-rbac-rules.yaml

# Extract controller ClusterRole rules from rendered Helm template
helm template test-release deploy/helm/rds-csi-driver/ --namespace rds-csi \
  | yq 'select(.kind == "ClusterRole" and .metadata.name == "*-controller-role") | .rules' > /tmp/helm-rbac-rules.yaml

# Diff the two (should show no differences in rule content, only formatting)
diff /tmp/existing-rbac-rules.yaml /tmp/helm-rbac-rules.yaml
```
If yq is not available, use `nix-shell -p yq-go` or manually compare the rules sections. The diff must show zero substantive differences -- only name/label changes are acceptable.
  </verify>
  <done>Four template files render correctly. RBAC preserves all existing rules (verified by diff against deploy/kubernetes/rbac.yaml). All namespace references use {{ .Release.Namespace }}. CSIDriver spec matches existing manifest exactly.</done>
</task>

<task type="auto">
  <name>Task 2: Create controller Deployment and node DaemonSet templates</name>
  <files>
    deploy/helm/rds-csi-driver/templates/controller.yaml
    deploy/helm/rds-csi-driver/templates/node.yaml
  </files>
  <action>
**controller.yaml** - Convert deploy/kubernetes/controller.yaml to Helm template:

The controller Deployment must include:
1. **Metadata**: name `{{ include "rds-csi.fullname" . }}-controller`, namespace `{{ .Release.Namespace }}`, labels with component=controller
2. **Spec**: replicas from `.Values.controller.replicas`, selector with selectorLabels + component=controller
3. **Pod spec**: serviceAccountName `{{ include "rds-csi.fullname" . }}-controller`, priorityClassName from `.Values.controller.priorityClassName`
4. **Scheduling**: nodeSelector, tolerations, affinity all from `.Values.controller.*` using `with` blocks and `toYaml | nindent`

5. **Container: rds-csi-driver** -- This is the main driver container:
   - Image: `{{ .Values.controller.image.repository }}:{{ .Values.controller.image.tag | default .Chart.AppVersion }}`
   - imagePullPolicy from values
   - Args (matching main.go flags EXACTLY):
     - `-endpoint=$(CSI_ENDPOINT)`
     - `-node-id=$(NODE_ID)`
     - `-controller`
     - `-rds-address={{ .Values.rds.managementIP }}`
     - `-rds-port={{ .Values.rds.sshPort }}`
     - `-rds-user={{ .Values.rds.sshUser }}`
     - `-rds-key-file=/etc/rds-csi/rds-private-key` (HARDCODED path -- matches existing Secret key name from deploy/kubernetes/controller.yaml, NOT the main.go default of /etc/rds-csi/ssh-key/id_rsa)
     - `-rds-host-key=/etc/rds-csi/rds-host-key` (HARDCODED path -- matches existing Secret key name)
     - `-rds-volume-base-path={{ .Values.rds.basePath }}`
     - `-v={{ .Values.controller.logLevel }}`
     - `-metrics-address=:{{ .Values.monitoring.port }}` (conditional on monitoring.enabled)
     - Conditional: if `.Values.rds.insecureSkipVerify`: `-rds-insecure-skip-verify=true`
     - Conditional orphan reconciler args from `.Values.controller.orphanReconciler.*`
     - Conditional VMI serialization args from `.Values.controller.vmiSerialization.*`
     - Attachment management args: `-attachment-grace-period={{ .Values.controller.attachmentGracePeriod }}`, `-attachment-reconcile-interval={{ .Values.controller.attachmentReconcileInterval }}`
   - Env: CSI_ENDPOINT=unix:///var/lib/csi/sockets/pluginproxy/csi.sock, NODE_ID from fieldRef spec.nodeName
   - VolumeMounts: socket-dir at /var/lib/csi/sockets/pluginproxy/, rds-credentials at /etc/rds-csi (readOnly)
   - Resources from `.Values.controller.resources`

6. **Container: csi-provisioner** -- Image from `.Values.sidecars.provisioner.*`:
   - Args: `--csi-address=$(ADDRESS)`, `--leader-election=true`, `--leader-election-namespace={{ .Release.Namespace }}`, `--v=5`, plus additionalArgs loop
   - Env: ADDRESS=/var/lib/csi/sockets/pluginproxy/csi.sock
   - VolumeMounts: socket-dir
   - Resources from values

7. **Container: csi-attacher** -- Same pattern as provisioner with `.Values.sidecars.attacher.*`
8. **Container: csi-resizer** -- Same pattern with `.Values.sidecars.resizer.*`
9. **Container: csi-snapshotter** -- Same pattern with `.Values.sidecars.snapshotter.*`
10. **Container: liveness-probe** -- Image from `.Values.sidecars.livenessProbe.*`, args: `--csi-address=$(ADDRESS)`, `--v=5`

11. **Volumes**: socket-dir (emptyDir), rds-credentials (secret from `.Values.rds.secretName`, defaultMode 0400)

The secret volume MUST reference `.Values.rds.secretName`:
```yaml
      - name: rds-credentials
        secret:
          secretName: {{ .Values.rds.secretName }}
          defaultMode: 0400
```
This ensures the controller will fail at runtime with a clear error if the user has not created the Secret. The chart intentionally does NOT create the Secret (per CONTEXT.md: "user creates Secret first, chart references via rds.secretName").

**node.yaml** - Convert deploy/kubernetes/node.yaml to Helm template:

The node DaemonSet must include:
1. **Metadata**: name `{{ include "rds-csi.fullname" . }}-node`, labels with component=node
2. **UpdateStrategy**: RollingUpdate, maxUnavailable 1
3. **Pod spec**: serviceAccountName `{{ include "rds-csi.fullname" . }}-node`, hostNetwork: true, dnsPolicy: ClusterFirstWithHostNet, priorityClassName from values, terminationGracePeriodSeconds from values
4. **Security**: seccompProfile RuntimeDefault (pod-level)
5. **Scheduling**: nodeSelector, tolerations from `.Values.node.*`

6. **Container: rds-csi-driver** -- Node mode:
   - Image from `.Values.node.image.*`
   - Args: `-endpoint=$(CSI_ENDPOINT)`, `-node-id=$(NODE_ID)`, `-node`, `-v={{ .Values.node.logLevel }}`
   - Conditional metrics: `-metrics-address=:{{ .Values.monitoring.port }}` (if monitoring.enabled)
   - Env: CSI_ENDPOINT=unix:///csi/csi.sock, NODE_ID from fieldRef, CSI_MANAGED_NQN_PREFIX from `.Values.rds.nqnPrefix`
   - SecurityContext: privileged=true, readOnlyRootFilesystem=true, runAsUser=0
   - VolumeMounts: plugin-dir at /csi, pods-mount-dir at kubeletPath (Bidirectional), device-dir at /dev, sys-dir at /sys (HostToContainer), tmp, var-run
   - Resources from values

7. **Container: node-driver-registrar** -- Image from `.Values.node.registrar.*`:
   - Args: `--csi-address=$(ADDRESS)`, `--kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)`, `--v=5`
   - Env: ADDRESS=/csi/csi.sock, DRIVER_REG_SOCK_PATH={{ .Values.node.kubeletPath }}/plugins/rds.csi.srvlab.io/csi.sock, KUBE_NODE_NAME from fieldRef
   - VolumeMounts: plugin-dir, registration-dir
   - Resources from values

8. **Container: liveness-probe** -- Image from `.Values.node.livenessProbe.*`:
   - Same as controller liveness probe but with node socket path /csi/csi.sock

9. **Volumes**: plugin-dir (hostPath: kubeletPath/plugins/rds.csi.srvlab.io/, DirectoryOrCreate), registration-dir (hostPath: kubeletPath/plugins_registry/, Directory), pods-mount-dir (hostPath: kubeletPath, Directory), device-dir (/dev, Directory), sys-dir (/sys, Directory), tmp (emptyDir), var-run (emptyDir)

CRITICAL: The kubeletPath value MUST be used consistently in hostPath volumes. Use `{{ .Values.node.kubeletPath }}` not hardcoded /var/lib/kubelet.

After creating both templates, run `helm template test-release deploy/helm/rds-csi-driver/ --namespace rds-csi` and verify the output matches the existing deploy/kubernetes/ manifests in structure (container names, volume mounts, security contexts). Differences should only be in names (templated) and namespace (templated).
  </action>
  <verify>
Run `helm template test-release deploy/helm/rds-csi-driver/ --namespace rds-csi | grep -c "kind:"` to count generated resources. Run `helm lint deploy/helm/rds-csi-driver/` to verify no errors. Visually compare `helm template` output against existing deploy/kubernetes/ manifests to confirm all containers, volumes, and args are present. Verify the rds-credentials volume references `.Values.rds.secretName` and mounts at `/etc/rds-csi` with key paths `rds-private-key` and `rds-host-key`.
  </verify>
  <done>Controller Deployment has 6 containers (driver + 5 sidecars) with all args from main.go templated. Secret key file paths are /etc/rds-csi/rds-private-key and /etc/rds-csi/rds-host-key (matching deployed manifests). Node DaemonSet has 3 containers with privileged security context, hostNetwork, and bidirectional mount propagation preserved. helm template renders valid YAML matching existing manifest structure.</done>
</task>

</tasks>

<verification>
1. `helm lint deploy/helm/rds-csi-driver/` passes with no errors
2. `helm template test-release deploy/helm/rds-csi-driver/ --namespace rds-csi` renders all resources:
   - ServiceAccounts (2)
   - ClusterRoles (2)
   - ClusterRoleBindings (2)
   - CSIDriver (1)
   - Deployment (1)
   - DaemonSet (1)
3. Controller has 6 containers: rds-csi-driver, csi-provisioner, csi-attacher, csi-resizer, csi-snapshotter, liveness-probe
4. Node has 3 containers: rds-csi-driver, node-driver-registrar, liveness-probe
5. All leader-election-namespace args use {{ .Release.Namespace }}
6. All RBAC rules match deploy/kubernetes/rbac.yaml exactly (verified via diff)
7. No hardcoded `rds-csi` namespace strings in templates (only {{ .Release.Namespace }})
8. Controller Secret volume references .Values.rds.secretName with mount at /etc/rds-csi
</verification>

<success_criteria>
- Core templates render resources equivalent to existing deploy/kubernetes/ manifests
- All container args match main.go flag names exactly
- Secret key file paths match deployed convention: /etc/rds-csi/rds-private-key, /etc/rds-csi/rds-host-key
- Namespace is configurable via helm install --namespace
- Resources, scheduling, and security contexts are configurable via values
- RBAC rules verified identical to source via diff command
- helm lint and helm template both succeed without errors
</success_criteria>

<output>
After completion, create `.planning/phases/28-helm-chart/28-02-SUMMARY.md`
</output>
