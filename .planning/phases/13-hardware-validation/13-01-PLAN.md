---
phase: 13-hardware-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - test/e2e/PROGRESSIVE_VALIDATION.md
  - test/e2e/HARDWARE_VALIDATION.md
autonomous: false

must_haves:
  truths:
    - "Basic volume operations (create/delete) work via SSH"
    - "Filesystem volumes can be staged, published, written to, and persist data"
    - "Block volumes work without filesystem formatting"
    - "Error resilience features (health check, circuit breaker) function correctly"
    - "RWO attachment conflicts are detected and enforced"
    - "KubeVirt VMs boot with RDS block volumes"
    - "KubeVirt live migration completes with data integrity preserved"
    - "Migration metrics are emitted"
  artifacts:
    - path: "test/e2e/PROGRESSIVE_VALIDATION.md"
      provides: "Comprehensive validation runbook with all test procedures"
      min_lines: 800
    - path: "test/e2e/HARDWARE_VALIDATION.md"
      provides: "Validation results and test summary"
      min_lines: 100
  key_links:
    - from: "Progressive validation runbook"
      to: "Hardware validation results"
      via: "Systematic execution of all test scenarios"
      pattern: "VAL-\\d{2}"
---

<objective>
Systematically validate RDS CSI driver functionality on metal cluster using progressive validation approach.

Purpose: Build confidence from basic operations through complex scenarios to KubeVirt live migration. This comprehensive validation proves the v0.6.0 implementation works in production with all Phase 14 safety features.

Approach: Execute test/e2e/PROGRESSIVE_VALIDATION.md runbook which covers 7 validation areas:
- VAL-01: Basic volume operations
- VAL-02: Filesystem volume lifecycle
- VAL-03: Block volume lifecycle
- VAL-04: Error resilience (health check, circuit breaker, graceful shutdown)
- VAL-05: Multi-node operations (RWO conflict detection)
- VAL-06: KubeVirt VM boot
- VAL-07: KubeVirt live migration

Output:
- Detailed validation results in HARDWARE_VALIDATION.md
- Any issues documented with resolutions
- v0.6.0 release readiness confirmed
</objective>

<execution_context>
@/Users/whiskey/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whiskey/.claude/get-shit-done/templates/summary.md
@test/e2e/PROGRESSIVE_VALIDATION.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-hardware-validation/13-CONTEXT.md
@.planning/phases/14-error-resilience-and-mount-storm-prevention/14-04-SUMMARY.md
@.planning/phases/11-block-volume-node-operations/11-03-SUMMARY.md
@.planning/phases/12-compatibility-and-quality/12-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pre-validation environment setup</name>
  <files>deploy/kubernetes/controller.yaml (ConfigMap verification)</files>
  <action>
  Prepare cluster for validation with Phase 14 safety features.

  1. Verify ConfigMap has nqn-prefix:
     ```bash
     kubectl -n rds-csi get configmap rds-csi-config -o yaml | grep nqn-prefix
     # Expected: nqn-prefix: nqn.2000-02.com.mikrotik:pvc-
     ```

  2. Build and push latest driver image:
     ```bash
     # Build with all Phase 14 features
     make docker
     docker tag ghcr.io/3whiskeywhiskey/rds-csi:dev ghcr.io/3whiskeywhiskey/rds-csi:v0.6.0-rc1
     docker push ghcr.io/3whiskeywhiskey/rds-csi:dev
     docker push ghcr.io/3whiskeywhiskey/rds-csi:v0.6.0-rc1
     ```

  3. Deploy updated driver:
     ```bash
     kubectl -n rds-csi rollout restart deployment rds-csi-controller
     kubectl -n rds-csi rollout restart daemonset rds-csi-node
     ```

  4. Wait for rollout to complete:
     ```bash
     kubectl -n rds-csi rollout status deployment rds-csi-controller --timeout=5m
     kubectl -n rds-csi rollout status daemonset rds-csi-node --timeout=5m
     ```

  5. Verify all pods healthy:
     ```bash
     kubectl -n rds-csi get pods -o wide
     # All pods should be Running with no restarts
     ```

  6. Check for CSI_MANAGED_NQN_PREFIX in node logs:
     ```bash
     kubectl -n rds-csi logs -l app=rds-csi-node --tail=20 | grep -i "nqn\|prefix"
     # Should show NQN prefix loaded from ConfigMap
     ```

  7. Clean up any previous test resources:
     ```bash
     kubectl delete pvc -l test=rds-csi-validation --all-namespaces
     kubectl delete pod -l test=rds-csi-validation --all-namespaces
     kubectl delete vm -l test=rds-csi-validation --all-namespaces
     ```
  </action>
  <verify>
  - ConfigMap has nqn-prefix key
  - Latest driver image built and pushed
  - All pods Running (controller + nodes)
  - No CrashLoopBackOff or errors in logs
  - NQN prefix loaded correctly on nodes
  - Previous test resources cleaned up
  </verify>
  <done>Environment ready for progressive validation</done>
</task>

<task type="auto">
  <name>Task 2: Execute VAL-01 through VAL-05 (Foundation tests)</name>
  <files>test/e2e/HARDWARE_VALIDATION.md</files>
  <action>
  Execute foundational validation tests from PROGRESSIVE_VALIDATION.md runbook.

  Follow the runbook procedures for:

  **VAL-01: Basic Volume Operations**
  - Create/delete filesystem PVC
  - Verify volume appears on RDS
  - Verify PV created and deleted

  **VAL-02: Filesystem Volume Lifecycle**
  - Create PVC with WaitForFirstConsumer
  - Stage, publish, write data
  - Verify data persists after remount
  - Unstage and cleanup

  **VAL-03: Block Volume Lifecycle**
  - Create block-mode PVC
  - Verify block device in pod
  - Write/read from block device
  - No filesystem formatting

  **VAL-04: Error Resilience**
  - Verify filesystem health check runs
  - Verify circuit breaker initialized
  - Test graceful shutdown timing

  **VAL-05: Multi-Node Operations**
  - Create RWO PVC on node A
  - Verify attachment conflict when attempting node B
  - Verify attachment succeeds after grace period

  Document results in HARDWARE_VALIDATION.md as you complete each test.
  Include:
  - Test name and objective
  - Commands executed
  - Actual vs expected results
  - Any issues encountered
  - Screenshots or log excerpts if relevant
  </action>
  <verify>
  - All VAL-01 through VAL-05 tests executed
  - Results documented in HARDWARE_VALIDATION.md
  - All foundational tests passed (or issues documented)
  </verify>
  <done>Foundation validation tests complete</done>
</task>

<task type="auto">
  <name>Task 3: Execute VAL-06 (KubeVirt VM Boot)</name>
  <files>test/e2e/HARDWARE_VALIDATION.md</files>
  <action>
  Execute KubeVirt VM boot test from PROGRESSIVE_VALIDATION.md runbook.

  Follow VAL-06 procedures:

  1. Create RWX block PVC (5Gi) for VM
  2. Create KubeVirt VM with cirros and RDS block volume
  3. Wait for VM to reach Running phase
  4. Access VM console (virtctl console)
  5. Verify block device visible (/dev/vdb)
  6. Create ext4 filesystem on block device
  7. Mount filesystem to /mnt/data
  8. Write test data (100MB random file)
  9. Generate and save checksum for migration validation
  10. Sync and exit console

  Document:
  - PVC creation and binding
  - VM startup time and node placement
  - Block device detection
  - Filesystem creation success
  - Checksum value for later comparison
  </action>
  <verify>
  - RWX block PVC bound successfully
  - VM reached Running phase
  - Block device visible as /dev/vdb in VM
  - Filesystem created and mounted
  - Test data written with checksum saved
  </verify>
  <done>KubeVirt VM boot validated with block volume</done>
</task>

<task type="auto">
  <name>Task 4: Execute VAL-07 (KubeVirt Live Migration)</name>
  <files>test/e2e/HARDWARE_VALIDATION.md</files>
  <action>
  Execute live migration test from PROGRESSIVE_VALIDATION.md runbook.

  Follow VAL-07 procedures:

  1. Record VM's current node
  2. Create VirtualMachineInstanceMigration object
  3. Watch migration progress (kubectl get vmim -w)
  4. Verify migration reaches Succeeded phase
  5. Confirm VM running on different node
  6. Access VM console on new node
  7. Mount /dev/vdb to /mnt/data
  8. Verify checksum matches pre-migration value
  9. Query controller metrics for migration stats
  10. Document migration duration and throughput

  Critical verification:
  - Checksum MUST match exactly (data integrity)
  - Migration metrics MUST be emitted
  - VM MUST be on different node

  Document:
  - Source and target nodes
  - Migration duration
  - Data integrity verification (checksum comparison)
  - Migration metrics values
  - Any warnings or errors during migration
  </action>
  <verify>
  - Migration completed (Succeeded phase)
  - VM migrated to different node
  - Data integrity verified (checksums match)
  - Migration metrics emitted (migrations_total, duration)
  - No data corruption or errors
  </verify>
  <done>Live migration validated end-to-end with data integrity</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
  Progressive hardware validation complete across 7 test areas:

  **Foundation (VAL-01 to VAL-05):**
  - Basic volume operations via SSH
  - Filesystem volume full lifecycle
  - Block volume operations
  - Error resilience features (health check, circuit breaker)
  - Multi-node RWO conflict detection

  **KubeVirt (VAL-06 to VAL-07):**
  - VM boot with RDS block volume
  - Live migration with data integrity
  - Migration metrics collection
  </what-built>
  <how-to-verify>
  Review test/e2e/HARDWARE_VALIDATION.md for complete results:

  1. **Foundation Tests (VAL-01 to VAL-05):**
     - All basic operations successful?
     - Data persistence verified?
     - Error resilience features working?
     - Attachment conflicts detected correctly?

  2. **KubeVirt Tests (VAL-06 to VAL-07):**
     - VM booted successfully?
     - Block device accessible in VM?
     - Migration completed to different node?
     - Checksums matched (data integrity)?
     - Migration metrics emitted?

  3. **Overall Assessment:**
     - Any critical failures?
     - Any non-critical issues to document?
     - Ready for v0.6.0 release?

  If all critical tests passed, type "validated" to proceed.
  If issues found, describe them for resolution or documentation.
  </how-to-verify>
  <resume-signal>Type "validated" if tests passed, or describe issues</resume-signal>
</task>

<task type="auto">
  <name>Task 5: Cleanup and finalize documentation</name>
  <files>test/e2e/HARDWARE_VALIDATION.md</files>
  <action>
  Clean up test resources and finalize validation documentation.

  1. Delete all test resources:
     ```bash
     # KubeVirt resources
     kubectl delete vm test-validation-vm
     kubectl delete vmim test-validation-migration

     # Test PVCs (with label selector)
     kubectl delete pvc -l test=rds-csi-validation --all-namespaces

     # Test pods
     kubectl delete pod -l test=rds-csi-validation --all-namespaces
     ```

  2. Verify cleanup on RDS:
     ```bash
     ssh metal-csi@10.42.241.3 '/disk print detail where slot~"pvc-"'
     # Should only show production volumes, no test volumes
     ```

  3. Finalize HARDWARE_VALIDATION.md using template from runbook:
     - Summary table with all 7 test results
     - Pass/fail status for each test
     - Total validation duration
     - Issues encountered and resolutions
     - Recommendations for operators
     - Sign-off checklist

  4. Review driver logs for any warnings or errors:
     ```bash
     kubectl -n rds-csi logs -l app=rds-csi-controller --tail=200 > controller-logs.txt
     kubectl -n rds-csi logs -l app=rds-csi-node --tail=200 > node-logs.txt
     # Attach relevant excerpts to documentation
     ```

  5. Verify no orphaned resources:
     ```bash
     kubectl get pv | grep rds-csi
     kubectl -n rds-csi get events --sort-by='.lastTimestamp' | tail -50
     ```
  </action>
  <verify>
  - All test resources deleted
  - No orphaned volumes on RDS
  - HARDWARE_VALIDATION.md complete with all results
  - Summary table filled out
  - Issues documented
  - Sign-off checklist complete
  </verify>
  <done>Validation complete and documented</done>
</task>

</tasks>

<verification>
All Phase 13 success criteria validated through progressive testing:

**Foundation:**
1. ✓ Basic volume create/delete operations work via SSH
2. ✓ Filesystem volumes support full lifecycle (stage/publish/data/persist/unstage)
3. ✓ Block volumes work without filesystem formatting
4. ✓ Error resilience features function (health check, circuit breaker, graceful shutdown)
5. ✓ RWO attachment conflicts detected and enforced

**KubeVirt:**
6. ✓ VMs boot successfully with RDS block volumes
7. ✓ Live migration completes end-to-end
8. ✓ Migration metrics emitted correctly
9. ✓ Data integrity preserved after migration (checksum validation)

**Documentation:**
10. ✓ Progressive validation runbook created (PROGRESSIVE_VALIDATION.md)
11. ✓ Hardware validation results documented (HARDWARE_VALIDATION.md)
</verification>

<success_criteria>
- test/e2e/PROGRESSIVE_VALIDATION.md exists with comprehensive test procedures (800+ lines)
- test/e2e/HARDWARE_VALIDATION.md exists with complete validation results (100+ lines)
- All 7 validation areas (VAL-01 through VAL-07) executed and documented
- All critical tests passed (or blockers documented for resolution)
- v0.6.0 Block Volume Support milestone validated for release
</success_criteria>

<output>
After completion, create `.planning/phases/13-hardware-validation/13-01-SUMMARY.md`
</output>
