---
phase: 31-scheduled-snapshots
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - deploy/helm/rds-csi-driver/values.yaml
  - deploy/helm/rds-csi-driver/values.schema.json
  - deploy/helm/rds-csi-driver/templates/_helpers.tpl
  - deploy/helm/rds-csi-driver/templates/scheduled-snapshots.yaml
  - deploy/helm/rds-csi-driver/templates/NOTES.txt
autonomous: true

must_haves:
  truths:
    - "A CronJob runs on a user-configured schedule and creates a VolumeSnapshot targeting a specified PVC"
    - "Snapshots older than the configured retention age are deleted, always keeping at least N most recent"
    - "helm install with scheduledSnapshots enabled deploys the CronJob; helm uninstall removes it cleanly"
    - "helm install with scheduledSnapshots disabled (default) deploys nothing extra"
  artifacts:
    - path: "deploy/helm/rds-csi-driver/templates/scheduled-snapshots.yaml"
      provides: "CronJob, ServiceAccount, Role, RoleBinding for scheduled snapshot creation and retention cleanup"
      contains: "kind: CronJob"
    - path: "deploy/helm/rds-csi-driver/values.yaml"
      provides: "scheduledSnapshots configuration section with schedule, retention, PVC target"
      contains: "scheduledSnapshots:"
    - path: "deploy/helm/rds-csi-driver/values.schema.json"
      provides: "JSON Schema validation for scheduledSnapshots values"
      contains: "scheduledSnapshots"
  key_links:
    - from: "deploy/helm/rds-csi-driver/templates/scheduled-snapshots.yaml"
      to: "deploy/helm/rds-csi-driver/values.yaml"
      via: "Helm template values"
      pattern: "\\.Values\\.scheduledSnapshots"
    - from: "deploy/helm/rds-csi-driver/templates/scheduled-snapshots.yaml"
      to: "snapshot.storage.k8s.io/v1"
      via: "kubectl create VolumeSnapshot in job script"
      pattern: "VolumeSnapshot"
---

<objective>
Implement a Helm-deployed CronJob that automatically creates VolumeSnapshots for a target PVC on a configurable schedule, with retention-based cleanup that deletes old snapshots while keeping the N most recent.

Purpose: Users need automated periodic snapshots for data protection without manually creating VolumeSnapshot resources. A CronJob is the simplest Kubernetes-native approach (no operator needed).

Output: Helm chart template files, values configuration, and schema validation for scheduled snapshots.
</objective>

<execution_context>
@/Users/whiskey/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whiskey/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@deploy/helm/rds-csi-driver/values.yaml
@deploy/helm/rds-csi-driver/values.schema.json
@deploy/helm/rds-csi-driver/templates/_helpers.tpl
@deploy/helm/rds-csi-driver/templates/snapshotclass.yaml
@deploy/helm/rds-csi-driver/templates/rbac.yaml
@deploy/helm/rds-csi-driver/templates/NOTES.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add scheduled snapshot values, schema, and helper template</name>
  <files>
    deploy/helm/rds-csi-driver/values.yaml
    deploy/helm/rds-csi-driver/values.schema.json
    deploy/helm/rds-csi-driver/templates/_helpers.tpl
  </files>
  <action>
1. Add `scheduledSnapshots` section to `values.yaml` (after the `snapshotClass` section, before `namespace`):

```yaml
# Scheduled snapshot configuration
# Creates a CronJob that periodically snapshots a target PVC
scheduledSnapshots:
  # Enable scheduled snapshots (requires snapshotClass.enabled=true)
  enabled: false

  # List of snapshot schedules (one CronJob per entry)
  schedules:
    - name: daily-snapshot
      # Target PVC name to snapshot
      pvcName: ""
      # Cron schedule expression (default: daily at 02:00)
      schedule: "0 2 * * *"
      # VolumeSnapshotClass to use (defaults to snapshotClass.name)
      snapshotClassName: ""
      # Retention policy
      retention:
        # Maximum number of snapshots to keep (always keeps at least this many regardless of age)
        maxCount: 7
        # Maximum age of snapshots (Go duration format: 168h = 7 days)
        maxAge: "168h"

  # Container image for kubectl (used to create/delete VolumeSnapshots)
  image:
    repository: bitnami/kubectl
    tag: "1.28"
    pullPolicy: IfNotPresent

  # Resource requests/limits for the CronJob pod
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 100m
      memory: 64Mi
```

2. Add `scheduledSnapshots` to `values.schema.json` in the top-level `properties` object:

```json
"scheduledSnapshots": {
  "type": "object",
  "description": "Scheduled snapshot configuration",
  "properties": {
    "enabled": {
      "type": "boolean",
      "description": "Enable scheduled snapshots"
    },
    "schedules": {
      "type": "array",
      "description": "List of snapshot schedules",
      "items": {
        "type": "object",
        "required": ["name", "pvcName"],
        "properties": {
          "name": {
            "type": "string",
            "description": "Schedule name (used in CronJob and snapshot names)",
            "pattern": "^[a-z0-9]([-a-z0-9]*[a-z0-9])?$",
            "maxLength": 63
          },
          "pvcName": {
            "type": "string",
            "description": "Target PVC name to snapshot"
          },
          "schedule": {
            "type": "string",
            "description": "Cron schedule expression"
          },
          "snapshotClassName": {
            "type": "string",
            "description": "VolumeSnapshotClass name"
          },
          "retention": {
            "type": "object",
            "properties": {
              "maxCount": {
                "type": "integer",
                "description": "Maximum number of snapshots to keep",
                "minimum": 1
              },
              "maxAge": {
                "type": "string",
                "description": "Maximum age of snapshots (Go duration format)"
              }
            }
          }
        }
      }
    },
    "image": {
      "type": "object",
      "description": "kubectl container image",
      "properties": {
        "repository": {
          "type": "string"
        },
        "tag": {
          "type": "string"
        },
        "pullPolicy": {
          "type": "string",
          "enum": ["Always", "IfNotPresent", "Never"]
        }
      }
    }
  }
}
```

3. Add a helper template to `_helpers.tpl` for the snapshot schedule ServiceAccount name:

```
{{/*
Scheduled snapshot ServiceAccount name
*/}}
{{- define "rds-csi.snapshotScheduleServiceAccountName" -}}
{{- printf "%s-snapshot-scheduler" (include "rds-csi.fullname" .) }}
{{- end }}
```
  </action>
  <verify>
Run `nix-shell -p kubernetes-helm --run "helm template test deploy/helm/rds-csi-driver/"` to verify the chart templates render without errors with default values (scheduledSnapshots.enabled=false should produce no CronJob resources).
  </verify>
  <done>values.yaml contains scheduledSnapshots section with enabled=false default; schema validates the new fields; helper template defines ServiceAccount name.</done>
</task>

<task type="auto">
  <name>Task 2: Create CronJob template with snapshot creation and retention cleanup</name>
  <files>
    deploy/helm/rds-csi-driver/templates/scheduled-snapshots.yaml
  </files>
  <action>
Create `deploy/helm/rds-csi-driver/templates/scheduled-snapshots.yaml` containing all resources for scheduled snapshots, gated by `{{- if .Values.scheduledSnapshots.enabled }}`. All resources in a single file for clean install/uninstall.

The file should contain these resources (separated by `---`), all wrapped in the enabled check:

**1. ServiceAccount** for the CronJob pods:
- Name: `{{ include "rds-csi.snapshotScheduleServiceAccountName" . }}`
- Namespace: `{{ .Release.Namespace }}`
- Standard labels from `rds-csi.labels` plus `app.kubernetes.io/component: snapshot-scheduler`

**2. Role** (namespaced, NOT ClusterRole -- snapshots are namespace-scoped):
- Name: `{{ include "rds-csi.fullname" . }}-snapshot-scheduler`
- Rules:
  - `apiGroups: ["snapshot.storage.k8s.io"]`, resources: `["volumesnapshots"]`, verbs: `["get", "list", "create", "delete"]`
  - `apiGroups: [""]`, resources: `["persistentvolumeclaims"]`, verbs: `["get"]` (to verify PVC exists before snapshotting)

**3. RoleBinding** binding the Role to the ServiceAccount.

**4. CronJob** (one per schedule entry, range over `.Values.scheduledSnapshots.schedules`):
- Name: `{{ include "rds-csi.fullname" $ }}-{{ $schedule.name }}`
- Namespace: `{{ $.Release.Namespace }}`
- Labels: standard labels plus `app.kubernetes.io/component: snapshot-scheduler`
- `spec.schedule`: `{{ $schedule.schedule | default "0 2 * * *" }}`
- `spec.concurrencyPolicy`: Forbid (prevent overlapping jobs)
- `spec.successfulJobsHistoryLimit`: 3
- `spec.failedJobsHistoryLimit`: 3
- `spec.jobTemplate.spec.backoffLimit`: 1
- `spec.jobTemplate.spec.template.spec`:
  - `serviceAccountName`: the snapshot scheduler SA
  - `restartPolicy`: Never
  - `containers`: single container named `snapshot-manager`
    - Image: `{{ $.Values.scheduledSnapshots.image.repository }}:{{ $.Values.scheduledSnapshots.image.tag }}`
    - `imagePullPolicy`: from values
    - Resources: from values
    - Command: `/bin/sh`, args: `-c` with an inline script

**The inline script** must do two things in sequence:

**Part A - Create snapshot:**
```sh
SNAPSHOT_NAME="{{ $schedule.name }}-$(date +%Y%m%d-%H%M%S)"
PVC_NAME="{{ $schedule.pvcName }}"
SNAPSHOT_CLASS="{{ $schedule.snapshotClassName | default $.Values.snapshotClass.name }}"
NAMESPACE="{{ $.Release.Namespace }}"

echo "Creating snapshot ${SNAPSHOT_NAME} for PVC ${PVC_NAME}"

# Verify PVC exists
if ! kubectl get pvc "${PVC_NAME}" -n "${NAMESPACE}" > /dev/null 2>&1; then
  echo "ERROR: PVC ${PVC_NAME} not found in namespace ${NAMESPACE}"
  exit 1
fi

# Create VolumeSnapshot
cat <<SNAP_EOF | kubectl apply -f -
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: ${SNAPSHOT_NAME}
  namespace: ${NAMESPACE}
  labels:
    app.kubernetes.io/managed-by: rds-csi-snapshot-scheduler
    rds-csi.srvlab.io/schedule: "{{ $schedule.name }}"
    rds-csi.srvlab.io/pvc: "{{ $schedule.pvcName }}"
spec:
  volumeSnapshotClassName: ${SNAPSHOT_CLASS}
  source:
    persistentVolumeClaimName: ${PVC_NAME}
SNAP_EOF

echo "Snapshot ${SNAPSHOT_NAME} created successfully"
```

**Part B - Retention cleanup:**
```sh
MAX_COUNT={{ $schedule.retention.maxCount | default 7 }}
MAX_AGE="{{ $schedule.retention.maxAge | default "168h" }}"

echo "Running retention cleanup: maxCount=${MAX_COUNT}, maxAge=${MAX_AGE}"

# Convert maxAge to seconds for comparison
# Support hours (h) format: strip trailing 'h' and multiply by 3600
MAX_AGE_HOURS=$(echo "${MAX_AGE}" | sed 's/h$//')
MAX_AGE_SECONDS=$((MAX_AGE_HOURS * 3600))
NOW=$(date +%s)

# Get all snapshots for this schedule, sorted by creation time (oldest first)
SNAPSHOTS=$(kubectl get volumesnapshot -n "${NAMESPACE}" \
  -l "rds-csi.srvlab.io/schedule={{ $schedule.name }}" \
  -o jsonpath='{range .items[*]}{.metadata.name} {.metadata.creationTimestamp}{"\n"}{end}' \
  | sort -k2)

TOTAL=$(echo "${SNAPSHOTS}" | grep -c . || true)
echo "Found ${TOTAL} snapshots for schedule {{ $schedule.name }}"

# If total <= maxCount, only delete by age
# If total > maxCount, delete oldest until we reach maxCount, respecting age
DELETED=0
KEPT=0

echo "${SNAPSHOTS}" | while IFS=' ' read -r SNAP_NAME SNAP_TIME; do
  [ -z "${SNAP_NAME}" ] && continue

  # Calculate age in seconds
  SNAP_EPOCH=$(date -d "${SNAP_TIME}" +%s 2>/dev/null || date -jf "%Y-%m-%dT%H:%M:%SZ" "${SNAP_TIME}" +%s 2>/dev/null || echo 0)
  AGE_SECONDS=$((NOW - SNAP_EPOCH))

  REMAINING=$((TOTAL - DELETED))

  # Never delete if we'd go below maxCount
  if [ "${REMAINING}" -le "${MAX_COUNT}" ]; then
    echo "Keeping ${SNAP_NAME} (at minimum count ${MAX_COUNT})"
    continue
  fi

  # Delete if older than maxAge
  if [ "${AGE_SECONDS}" -gt "${MAX_AGE_SECONDS}" ]; then
    echo "Deleting ${SNAP_NAME} (age: $((AGE_SECONDS / 3600))h, exceeds ${MAX_AGE})"
    kubectl delete volumesnapshot "${SNAP_NAME}" -n "${NAMESPACE}" --ignore-not-found
    DELETED=$((DELETED + 1))
  else
    echo "Keeping ${SNAP_NAME} (age: $((AGE_SECONDS / 3600))h, within ${MAX_AGE})"
  fi
done

echo "Retention cleanup complete"
```

IMPORTANT: The inline script needs careful Helm template escaping. Use `{{` `}}` for Helm template directives and make sure shell `$()` and `${}` are NOT interpreted by Helm. Since these are inside a YAML string value (the arg to `-c`), Helm will only process `{{ }}` delimiters. Shell variable expansion (`$VAR`, `${VAR}`, `$(cmd)`) is fine as-is because they run at container runtime, not template time.

Ensure the `DELETED` variable works correctly across the while loop by using a temporary file or restructuring to avoid subshell issues with piped `while read`. A cleaner approach: collect snapshot names into an array-like structure first, count them, then iterate with index tracking.

Alternative approach for the retention loop that avoids pipe/subshell issues:

```sh
# Write snapshots to temp file
kubectl get volumesnapshot -n "${NAMESPACE}" \
  -l "rds-csi.srvlab.io/schedule={{ $schedule.name }}" \
  -o jsonpath='{range .items[*]}{.metadata.name} {.metadata.creationTimestamp}{"\n"}{end}' \
  | sort -k2 > /tmp/snapshots.txt

TOTAL=$(wc -l < /tmp/snapshots.txt | tr -d ' ')
echo "Found ${TOTAL} snapshots for schedule {{ $schedule.name }}"

DELETED=0
while IFS=' ' read -r SNAP_NAME SNAP_TIME; do
  [ -z "${SNAP_NAME}" ] && continue
  SNAP_EPOCH=$(date -d "${SNAP_TIME}" +%s 2>/dev/null || date -jf "%Y-%m-%dT%H:%M:%SZ" "${SNAP_TIME}" +%s 2>/dev/null || echo 0)
  AGE_SECONDS=$((NOW - SNAP_EPOCH))
  REMAINING=$((TOTAL - DELETED))
  if [ "${REMAINING}" -le "${MAX_COUNT}" ]; then
    echo "Keeping ${SNAP_NAME} (at minimum count ${MAX_COUNT})"
    continue
  fi
  if [ "${AGE_SECONDS}" -gt "${MAX_AGE_SECONDS}" ]; then
    echo "Deleting ${SNAP_NAME} (age: $((AGE_SECONDS / 3600))h, exceeds ${MAX_AGE})"
    kubectl delete volumesnapshot "${SNAP_NAME}" -n "${NAMESPACE}" --ignore-not-found
    DELETED=$((DELETED + 1))
  else
    echo "Keeping ${SNAP_NAME} (age: $((AGE_SECONDS / 3600))h, within ${MAX_AGE})"
  fi
done < /tmp/snapshots.txt
```

Use this temp-file approach to avoid the subshell variable scope issue.

Note on `date` parsing: The container image is `bitnami/kubectl` which is Debian-based, so `date -d` (GNU date) will work. No need for the macOS `-jf` fallback in the container, but it's harmless to keep it.
  </action>
  <verify>
1. Run `nix-shell -p kubernetes-helm --run "helm template test deploy/helm/rds-csi-driver/ --set scheduledSnapshots.enabled=true --set 'scheduledSnapshots.schedules[0].name=daily' --set 'scheduledSnapshots.schedules[0].pvcName=my-pvc'"` and verify it renders:
   - A ServiceAccount
   - A Role with volumesnapshot permissions
   - A RoleBinding
   - A CronJob with the correct schedule, image, and inline script

2. Run `nix-shell -p kubernetes-helm --run "helm template test deploy/helm/rds-csi-driver/"` (defaults) and verify NO scheduled snapshot resources appear.

3. Run `nix-shell -p kubernetes-helm --run "helm template test deploy/helm/rds-csi-driver/ --set scheduledSnapshots.enabled=true --set 'scheduledSnapshots.schedules[0].name=hourly' --set 'scheduledSnapshots.schedules[0].pvcName=data-pvc' --set 'scheduledSnapshots.schedules[0].schedule=0 * * * *' --set 'scheduledSnapshots.schedules[0].retention.maxCount=24' --set 'scheduledSnapshots.schedules[0].retention.maxAge=48h'"` and verify custom values appear in rendered output.
  </verify>
  <done>CronJob template renders correctly when enabled, produces no resources when disabled, creates VolumeSnapshot with proper labels, and runs retention cleanup respecting both maxCount and maxAge.</done>
</task>

<task type="auto">
  <name>Task 3: Update NOTES.txt with scheduled snapshot information</name>
  <files>
    deploy/helm/rds-csi-driver/templates/NOTES.txt
  </files>
  <action>
Add a new section to NOTES.txt (after the Snapshot Support section, before the Monitoring section) that is conditionally rendered when `scheduledSnapshots.enabled` is true:

```
{{- if .Values.scheduledSnapshots.enabled }}
================================================================================
Scheduled Snapshots
================================================================================

Automated snapshot schedules have been configured:
{{- range .Values.scheduledSnapshots.schedules }}

- {{ .name }}:
  PVC: {{ .pvcName }}
  Schedule: {{ .schedule | default "0 2 * * *" }}
  Retention: keep {{ .retention.maxCount | default 7 }} snapshots, max age {{ .retention.maxAge | default "168h" }}
{{- end }}

To check CronJob status:

  kubectl get cronjobs -n {{ .Release.Namespace }} -l app.kubernetes.io/component=snapshot-scheduler

To view recent snapshot jobs:

  kubectl get jobs -n {{ .Release.Namespace }} -l app.kubernetes.io/component=snapshot-scheduler

To view created snapshots for a schedule:

  kubectl get volumesnapshot -n {{ .Release.Namespace }} -l rds-csi.srvlab.io/schedule=<schedule-name>

{{- end }}
```

This gives users immediate visibility into what was configured and how to monitor it.
  </action>
  <verify>
Run `nix-shell -p kubernetes-helm --run "helm template test deploy/helm/rds-csi-driver/ --set scheduledSnapshots.enabled=true --set 'scheduledSnapshots.schedules[0].name=daily' --set 'scheduledSnapshots.schedules[0].pvcName=my-pvc' --show-only templates/NOTES.txt"` and verify the Scheduled Snapshots section appears with correct values.
  </verify>
  <done>NOTES.txt shows scheduled snapshot configuration when enabled and omits the section when disabled.</done>
</task>

</tasks>

<verification>
1. `helm template` with defaults renders no scheduled snapshot resources
2. `helm template` with `scheduledSnapshots.enabled=true` and a schedule entry renders ServiceAccount, Role, RoleBinding, and CronJob
3. CronJob spec has correct schedule, concurrencyPolicy=Forbid, and the inline script creates a VolumeSnapshot and runs retention cleanup
4. Snapshot labels include `rds-csi.srvlab.io/schedule` and `rds-csi.srvlab.io/pvc` for retention filtering
5. Retention logic respects both maxCount (never deletes below this) and maxAge (deletes older snapshots above maxCount)
6. `helm template` with multiple schedule entries produces one CronJob per schedule
7. NOTES.txt conditionally displays scheduled snapshot information
</verification>

<success_criteria>
- SCHED-01: CronJob creates VolumeSnapshot on configurable schedule (verified by helm template rendering correct CronJob spec with VolumeSnapshot creation in inline script)
- SCHED-02: Retention cleanup deletes snapshots older than configurable age while keeping maxCount most recent (verified by inline script logic in rendered CronJob)
- SCHED-03: CronJob template included in Helm chart (verified by helm template rendering and clean enable/disable toggle)
</success_criteria>

<output>
After completion, create `.planning/phases/31-scheduled-snapshots/31-01-SUMMARY.md`
</output>
