---
phase: 02-stale-mount-detection
plan: 04
type: execute
wave: 3
depends_on: ["02-02", "02-03"]
files_modified:
  - pkg/driver/node.go
autonomous: true

must_haves:
  truths:
    - "NodePublishVolume checks for stale mount before bind mount"
    - "NodeGetVolumeStats checks for stale mount before reporting stats"
    - "Stale mounts trigger automatic recovery transparently"
    - "Unrecoverable mount failures post events to PVC"
  artifacts:
    - path: "pkg/driver/node.go"
      provides: "CSI node operations with stale mount detection"
      contains: "checkAndRecoverMount"
  key_links:
    - from: "pkg/driver/node.go"
      to: "pkg/mount/stale.go"
      via: "StaleMountChecker.IsMountStale"
      pattern: "IsMountStale"
    - from: "pkg/driver/node.go"
      to: "pkg/mount/recovery.go"
      via: "MountRecoverer.Recover"
      pattern: "Recover"
    - from: "pkg/driver/node.go"
      to: "pkg/driver/events.go"
      via: "EventPoster.PostMountFailure"
      pattern: "PostMountFailure"
---

<objective>
Integrate stale mount detection and recovery into CSI node operations

Purpose: Wire up detection and recovery into NodePublishVolume and NodeGetVolumeStats. These are the operations that interact with mounted volumes - perfect points to detect and recover from stale state.

Output: Modified node.go with stale mount checking integrated into CSI operations
</objective>

<execution_context>
@/Users/whiskey/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whiskey/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-stale-mount-detection/02-CONTEXT.md
@.planning/phases/02-stale-mount-detection/02-02-SUMMARY.md
@.planning/phases/02-stale-mount-detection/02-03-SUMMARY.md
@pkg/driver/node.go
@pkg/driver/events.go
@pkg/mount/stale.go
@pkg/mount/recovery.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add stale mount infrastructure to NodeServer</name>
  <files>pkg/driver/node.go</files>
  <action>
Add StaleMountChecker and MountRecoverer to NodeServer struct and initialize in constructor.

Modifications:

1. Add new fields to NodeServer:
```go
type NodeServer struct {
    csi.UnimplementedNodeServer
    driver       *Driver
    nvmeConn     nvme.Connector
    mounter      mount.Mounter
    nodeID       string
    eventPoster  *EventPoster
    staleChecker *mount.StaleMountChecker  // NEW
    recoverer    *mount.MountRecoverer     // NEW
}
```

2. Update NewNodeServer to initialize checkers:
```go
func NewNodeServer(driver *Driver, nodeID string, k8sClient kubernetes.Interface) *NodeServer {
    var eventPoster *EventPoster
    if k8sClient != nil {
        eventPoster = NewEventPoster(k8sClient)
    }

    m := mount.NewMounter()
    connector := nvme.NewConnector()

    // Create stale mount checker using connector's resolver
    staleChecker := mount.NewStaleMountChecker(connector.GetResolver())

    // Create recovery with default config
    recoverer := mount.NewMountRecoverer(
        mount.DefaultRecoveryConfig(),
        m,
        staleChecker,
    )

    return &NodeServer{
        driver:       driver,
        nvmeConn:     connector,
        mounter:      m,
        nodeID:       nodeID,
        eventPoster:  eventPoster,
        staleChecker: staleChecker,
        recoverer:    recoverer,
    }
}
```

3. Add GetResolver method to nvme.Connector interface if not present (check pkg/nvme/nvme.go).

4. Add helper method for stale mount check and recovery:
```go
// checkAndRecoverMount checks if staging mount is stale and attempts recovery
// Returns nil if mount is healthy or recovery succeeded
// Returns error if mount is stale and recovery failed
func (ns *NodeServer) checkAndRecoverMount(ctx context.Context, stagingPath, nqn, fsType string, mountOptions []string, pvcNamespace, pvcName, volumeID string) error {
    // Check for stale mount
    stale, reason, err := ns.staleChecker.IsMountStale(stagingPath, nqn)
    if err != nil {
        klog.Warningf("Failed to check mount staleness for %s: %v", stagingPath, err)
        // Don't fail the operation if we can't check - proceed optimistically
        return nil
    }

    if !stale {
        return nil
    }

    klog.Warningf("Stale mount detected at %s (reason: %s), attempting recovery", stagingPath, reason)

    // Attempt recovery
    result, err := ns.recoverer.Recover(ctx, stagingPath, nqn, fsType, mountOptions)
    if err != nil {
        // Recovery failed - post event and return error
        if ns.eventPoster != nil {
            message := fmt.Sprintf("Mount recovery failed after %d attempts: %v (reason: %s, old device: %s)",
                result.Attempts, result.FinalError, reason, result.OldDevice)
            ns.eventPoster.PostRecoveryFailed(ctx, pvcNamespace, pvcName, volumeID, ns.nodeID, message)
        }
        return fmt.Errorf("mount recovery failed: %w", err)
    }

    klog.V(2).Infof("Mount recovery succeeded for %s (attempts: %d, device: %s -> %s)",
        stagingPath, result.Attempts, result.OldDevice, result.NewDevice)

    return nil
}
```
  </action>
  <verify>
go build ./pkg/driver/... compiles successfully
go vet ./pkg/driver/... passes
  </verify>
  <done>
NodeServer has staleChecker and recoverer fields
NewNodeServer initializes both checkers
checkAndRecoverMount helper method exists
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate stale checking into CSI operations</name>
  <files>pkg/driver/node.go</files>
  <action>
Add stale mount checking to NodePublishVolume and NodeGetVolumeStats.

Per CONTEXT.md: Check for staleness on every CSI node operation that accesses the mount.

1. Modify NodePublishVolume to check before bind mount:

After validating staging path is mounted, before bind mount:
```go
// Check if staging path is mounted
mounted, err := ns.mounter.IsLikelyMountPoint(stagingPath)
// ... existing checks ...

// NEW: Check for stale mount and attempt recovery
// Extract NQN from volume context or derive from volumeID
nqn := volumeContext[volumeContextNQN]
if nqn == "" {
    nqn, _ = volumeIDToNQN(volumeID)
}
if nqn != "" {
    fsType := defaultFSType
    if mnt := req.GetVolumeCapability().GetMount(); mnt != nil && mnt.FsType != "" {
        fsType = mnt.FsType
    }
    // Get mount options for recovery (same as original mount)
    stagingMountOptions := []string{} // Base options, not bind options
    if mnt := req.GetVolumeCapability().GetMount(); mnt != nil {
        stagingMountOptions = mnt.MountFlags
    }

    // Extract PVC info from volume context if available
    pvcNamespace := volumeContext["csi.storage.k8s.io/pvc/namespace"]
    pvcName := volumeContext["csi.storage.k8s.io/pvc/name"]

    if err := ns.checkAndRecoverMount(ctx, stagingPath, nqn, fsType, stagingMountOptions, pvcNamespace, pvcName, volumeID); err != nil {
        return nil, status.Errorf(codes.Internal, "stale mount recovery failed: %v", err)
    }
}

// ... continue with existing bind mount logic ...
```

2. Modify NodeGetVolumeStats to check before reporting:

Add stale check at the beginning after validation:
```go
// Validate request
// ... existing validation ...

// NEW: Check for stale mount if we can derive NQN
// For stats, we just need to verify mount is healthy
nqn, err := volumeIDToNQN(volumeID)
if err == nil && ns.staleChecker != nil {
    stale, reason, checkErr := ns.staleChecker.IsMountStale(volumePath, nqn)
    if checkErr != nil {
        klog.V(4).Infof("Could not check mount staleness: %v", checkErr)
    } else if stale {
        // For GetVolumeStats, we report unhealthy rather than attempting recovery
        // Recovery should happen in NodePublishVolume when pod accesses volume
        klog.Warningf("Stale mount detected for volume %s at %s (reason: %s)", volumeID, volumePath, reason)
        return &csi.NodeGetVolumeStatsResponse{
            Usage: []*csi.VolumeUsage{},
            VolumeCondition: &csi.VolumeCondition{
                Abnormal: true,
                Message:  fmt.Sprintf("Stale mount detected: %s", reason),
            },
        }, nil
    }
}

// ... continue with existing stats logic ...
```

3. Consider NodeUnpublishVolume - no stale check needed (just unmounting).

4. Consider NodeUnstageVolume - no stale check needed (unmounting and disconnecting).

Key points:
- NodePublishVolume: Check and recover (this is where pods access volumes)
- NodeGetVolumeStats: Check and report condition (informational)
- Use VolumeCondition in stats response when stale detected
  </action>
  <verify>
go build ./pkg/driver/... compiles successfully
go vet ./pkg/driver/... passes
  </verify>
  <done>
NodePublishVolume checks for stale mount and attempts recovery before bind mount
NodeGetVolumeStats checks for stale mount and returns VolumeCondition if abnormal
Recovery failures result in events posted to PVC
  </done>
</task>

</tasks>

<verification>
1. go build ./pkg/driver/... - all files compile
2. go vet ./pkg/driver/... - no issues
3. NodePublishVolume includes stale mount check
4. NodeGetVolumeStats includes stale mount check with VolumeCondition
5. checkAndRecoverMount posts events on failure
</verification>

<success_criteria>
- NodePublishVolume checks staging path for staleness before bind mount
- NodeGetVolumeStats reports abnormal VolumeCondition when stale
- Recovery is attempted transparently in NodePublishVolume
- Unrecoverable failures post events to PVC
- All code compiles and passes vet
</success_criteria>

<output>
After completion, create `.planning/phases/02-stale-mount-detection/02-04-SUMMARY.md`
</output>
