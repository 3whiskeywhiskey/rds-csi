---
phase: 27-documentation-a-hardware-validation
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/TESTING.md
  - docs/ci-cd.md
autonomous: true

must_haves:
  truths:
    - "Contributor can run unit tests, integration tests, sanity tests, and E2E tests following documented steps"
    - "Contributor knows how to add a new CI test job with a documented template"
    - "Contributor can diagnose common test failures using symptom-driven troubleshooting flows"
    - "CI/CD guide explains how to interpret test results for each job type"
    - "Coverage goals and acceptable gaps are clearly documented per package"
  artifacts:
    - path: "docs/TESTING.md"
      provides: "Updated testing guide with troubleshooting flows and coverage goals"
      min_lines: 350
      contains: "Troubleshooting"
    - path: "docs/ci-cd.md"
      provides: "Updated CI/CD guide with 'how to add test job' section"
      min_lines: 280
      contains: "Adding a New Test Job"
  key_links:
    - from: "docs/TESTING.md"
      to: "docs/ci-cd.md"
      via: "cross-reference for CI test interpretation"
      pattern: "ci-cd.md"
    - from: "docs/ci-cd.md"
      to: ".github/workflows/"
      via: "links to actual workflow files"
      pattern: "workflows"
---

<objective>
Update TESTING.md with comprehensive troubleshooting decision trees and contributor guidance, and update ci-cd.md with "how to add new test jobs" and result interpretation guide.

Purpose: Contributors need clear documentation on running all test types and diagnosing failures. CI/CD documentation needs maintainable guidance for extending the test pipeline. Satisfies DOC-02 (testing guide), DOC-05 (CI/CD integration guide), and DOC-06 (troubleshooting guide).

Output: Updated docs/TESTING.md with expanded troubleshooting and contributor sections; updated docs/ci-cd.md with test job template and interpretation guide.
</objective>

<execution_context>
@/Users/whiskey/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whiskey/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@docs/TESTING.md
@docs/ci-cd.md
@CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Expand TESTING.md with troubleshooting and updated coverage info</name>
  <files>docs/TESTING.md</files>
  <action>
Update the existing docs/TESTING.md (do NOT rewrite from scratch -- preserve existing content and enhance it). Make these specific additions and updates:

**1. Update Coverage Goals section** (currently says ~60%, needs update to reflect v0.9.0 reality):
- Update "Current coverage" from ~60% to 68.6% (actual v0.9.0 figure)
- Update target to 65% minimum (CI-enforced threshold from Phase 25-04)
- Update package-level targets:
  - `pkg/driver` - Target: 70% (core CSI logic)
  - `pkg/rds` - Target: 50% (SSH-dependent)
  - `pkg/utils` - Target: 80% (pure functions)
  - `pkg/driver/attachment` - Target: 65% (reconciliation logic)
  - `pkg/driver/connection` - Target: 60% (connection manager)
- Add note: "CI enforces minimum 65% coverage. Coverage drops below this threshold will fail the build."

**2. Update "E2E Tests" reference** (currently says "planned"):
- E2E tests now exist in `test/e2e/` using Ginkgo v2 framework
- Running E2E: `make test-e2e`
- E2E tests run in CI via dedicated job (no real hardware needed)
- E2E tests use in-process driver with mock RDS for fast iteration
- Test suites: lifecycle_test.go (volume create/delete/expand), block_volume_test.go (block mode)

**3. Expand "Debugging Test Failures" section into comprehensive troubleshooting:**

Add new subsections following Pattern 5 from research (symptom-driven diagnostic flows):

**Troubleshooting: Unit Test Failures**
- "TestXxx fails with 'mock expectation not met'" -> Check mock setup matches new function signature
- "TestXxx fails with 'context deadline exceeded'" -> Test timeout too short for realistic mock timing
- "TestXxx fails with 'invalid IP address'" -> Ensure test uses valid IPv4 (not empty string or malformed)
- Fix: `go test -v -run TestXxx ./pkg/driver/... 2>&1 | head -50`

**Troubleshooting: Integration Test Failures**
- "Connection refused on port 2222" -> Mock RDS server failed to start; check port conflicts
- "Unexpected SSH command output" -> Mock RDS version mismatch; check MOCK_RDS_ROUTEROS_VERSION
- "State inconsistency between tests" -> Tests sharing mock; ensure fresh mock per test or ClearCommandHistory()
- Fix: `MOCK_RDS_ENABLE_HISTORY=true go test -v ./test/integration/... 2>&1`

**Troubleshooting: Sanity Test Failures**
- "CreateVolume idempotency check failed" -> Driver returning different volume ID for same name
- "DeleteVolume returned error for non-existent volume" -> Should return success (CSI spec requires idempotency)
- "Capability mismatch" -> Driver capabilities changed but sanity test config not updated
- Fix: `go test -v ./test/sanity/... -count=1 2>&1 | grep FAIL`

**Troubleshooting: E2E Test Failures**
- "Ginkgo timeout waiting for PVC" -> In-process driver startup slow; increase Eventually timeout
- "Volume not found after create" -> Race condition in mock; check thread safety
- "Block volume test skipped" -> Block volume support not detected; verify driver capabilities

**Troubleshooting: Mock-Reality Divergence**
This is a new subsection explaining the fundamental difference between mock and hardware testing:
- Mock RDS responds instantly; real RDS takes 10-30s for volume operations
- Mock doesn't simulate NVMe/TCP at all; real hardware has kernel device discovery timing
- Mock doesn't enforce disk capacity; real RDS can run out of space
- Mock command parsing may not match exact RouterOS output format across versions
- Recommendation: After making changes, validate against real hardware using HARDWARE_VALIDATION.md procedures

**4. Add "Hardware Integration Tests" section** (new, after E2E Tests):
- Reference existing `test/integration/hardware_integration_test.go`
- How to run: `RDS_ADDRESS=10.42.241.3 RDS_USER=admin RDS_PRIVATE_KEY_PATH=~/.ssh/id_rsa go test -v ./test/integration/ -run TestHardwareIntegration`
- These tests are skipped by default (require RDS_ADDRESS env var)
- Safe to run: creates test volume, verifies operations, deletes volume
- Link to docs/HARDWARE_VALIDATION.md for full manual validation procedures

**5. Update "Continuous Integration" section** to match current CI (3 jobs, not 2):
- Verify job: code quality + unit tests + integration tests
- Sanity-tests job: CSI spec compliance with mock RDS
- Build-test job: Docker image build verification
- E2E job: Full stack E2E tests with Ginkgo
- Link to docs/ci-cd.md for complete CI/CD documentation

Do NOT remove any existing content. Only add new sections and update outdated numbers/text.
  </action>
  <verify>
Run: `grep "68.6" docs/TESTING.md` - should show updated coverage figure.
Run: `grep -c "Troubleshooting" docs/TESTING.md` - should be 6+ (section headers).
Run: `grep "Mock-Reality" docs/TESTING.md` - should show the divergence section.
Run: `grep "HARDWARE_VALIDATION" docs/TESTING.md` - should cross-reference hardware validation.
Run: `grep "E2E" docs/TESTING.md` - should show E2E as implemented (not "planned").
Run: `wc -l docs/TESTING.md` - should be 350+ lines (was 413, adding content).
  </verify>
  <done>
TESTING.md is updated with: accurate coverage numbers (68.6%, 65% CI threshold), E2E tests documented as implemented, expanded troubleshooting with symptom-driven flows for each test type, mock-reality divergence section, hardware integration test instructions, and cross-references to HARDWARE_VALIDATION.md and ci-cd.md.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add test job template and result interpretation to ci-cd.md</name>
  <files>docs/ci-cd.md</files>
  <action>
Update existing docs/ci-cd.md to add two new sections. Insert them BEFORE the "Troubleshooting" section (around line 234). Do NOT remove existing content.

**Section 1: "Adding a New Test Job"**

Follow Pattern 7 from research (CI/CD Documentation Maintainability).

```markdown
## Adding a New Test Job

When you add a new test type that should gate merges, add a job to `.github/workflows/pr.yml`.

### Template

```yaml
  new-test-job:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod
      - name: Run tests
        run: make test-new-type
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: new-test-logs
          path: /tmp/test-output/
```

### Checklist for New Test Jobs

1. **Makefile target**: Add `test-new-type` target in Makefile before adding CI job
2. **Local verification**: Ensure `make test-new-type` passes locally
3. **Timeout**: Set job timeout (default: 10 minutes; extend for integration tests)
4. **Artifacts**: Always upload logs on failure for debugging
5. **Dependencies**: If test needs tools (nvme-cli, etc.), install in a setup step
6. **PR scope**: Run on all PRs (not just main) for early feedback

### Decision Guide

| Question | Yes | No |
|----------|-----|-----|
| Does it test spec compliance? | Run on all PRs | - |
| Does it need real hardware? | Manual only, don't add to CI | Run in CI |
| Does it take >10 minutes? | Consider running only on main | Run on all PRs |
| Does it test new capability? | Add as separate job (parallel) | Add to existing test job |
```

**Section 2: "Interpreting Test Results"**

```markdown
## Interpreting Test Results

When a CI job fails, use this guide to understand what went wrong and how to fix it.

### verify job
**What it tests:** Code formatting, static analysis, linting, unit tests, integration tests
**Common failure patterns:**

| Pattern | Cause | Fix |
|---------|-------|-----|
| `golangci-lint errors found` | New code violates linter rules | Run `make lint` locally, fix reported issues |
| `FAIL: TestXxx` | Unit test failure | Run `make test` locally, check specific test |
| `gofmt -d` shows diff | Code not formatted | Run `make fmt` |
| `go vet` findings | Suspicious code patterns | Address vet warnings |

### sanity-tests job
**What it tests:** CSI specification compliance using official csi-test package
**Common failure patterns:**

| Pattern | Cause | Fix |
|---------|-------|-----|
| `idempotency check failed` | CreateVolume/DeleteVolume not idempotent | Check volume name handling for duplicate requests |
| `capability not supported` | Driver reports capability but doesn't implement it | Update GetCapabilities or implement the RPC |
| `unexpected error code` | Wrong gRPC status code returned | Check CSI spec for required error codes per RPC |

**Debugging:** Download `sanity-test-logs` artifact from failed run for full output.

### e2e job
**What it tests:** Full-stack driver behavior with mock RDS
**Common failure patterns:**

| Pattern | Cause | Fix |
|---------|-------|-----|
| `Ginkgo timed out` | Eventually/Consistently timeout too short | Increase timeout in test, or check for deadlock |
| `expected volume to be bound` | Volume provisioning failed in mock | Check mock RDS state, verify CreateVolume logic |
| `block volume test failed` | Block volume capability issue | Verify BLOCK_VOLUME capability in driver |

### build-test job
**What it tests:** Docker image builds correctly for linux/amd64 and linux/arm64
**Common failure patterns:**

| Pattern | Cause | Fix |
|---------|-------|-----|
| `go build failed` | Compilation error | Fix build errors, ensure `make build` works locally |
| `docker buildx failed` | Dockerfile issue | Test with `make docker` locally |
```

Also add a cross-reference at the bottom of TESTING.md's CI section pointing to ci-cd.md, and a cross-reference from ci-cd.md back to TESTING.md.

Add to the bottom of ci-cd.md's existing content, before any trailing whitespace:
```markdown

## Related Documentation

- [Testing Guide](TESTING.md) - How to run tests locally and contribute new tests
- [Hardware Validation](HARDWARE_VALIDATION.md) - Manual testing procedures for production hardware
```
  </action>
  <verify>
Run: `grep "Adding a New Test Job" docs/ci-cd.md` - should show the new section.
Run: `grep "Interpreting Test Results" docs/ci-cd.md` - should show the new section.
Run: `grep -c "Pattern.*Cause.*Fix" docs/ci-cd.md` - should be 4+ (table headers).
Run: `grep "TESTING.md" docs/ci-cd.md` - should show cross-reference.
Run: `wc -l docs/ci-cd.md` - should be 280+ lines (was 320, adding significant content).
  </verify>
  <done>
ci-cd.md has "Adding a New Test Job" section with YAML template and checklist, "Interpreting Test Results" section with failure pattern tables for each CI job type, and cross-references to TESTING.md and HARDWARE_VALIDATION.md.
  </done>
</task>

</tasks>

<verification>
- TESTING.md has updated coverage numbers (68.6%, 65% CI threshold)
- TESTING.md has expanded troubleshooting with 5+ symptom categories
- TESTING.md documents E2E tests as implemented (not planned)
- TESTING.md has mock-reality divergence section
- ci-cd.md has "Adding a New Test Job" with YAML template
- ci-cd.md has "Interpreting Test Results" with per-job failure patterns
- Cross-references between TESTING.md, ci-cd.md, and HARDWARE_VALIDATION.md
</verification>

<success_criteria>
A new contributor can: (1) run all test types locally following TESTING.md, (2) diagnose a test failure using the troubleshooting section, (3) add a new CI test job following the template in ci-cd.md, (4) interpret a CI failure using the result interpretation guide.
</success_criteria>

<output>
After completion, create `.planning/phases/27-documentation-a-hardware-validation/27-03-SUMMARY.md`
</output>
