---
phase: 30-snapshot-validation
plan: 02
type: execute
wave: 2
depends_on: ["30-01"]
files_modified:
  - test/sanity/sanity_test.go
  - docs/HARDWARE_VALIDATION.md
autonomous: true

must_haves:
  truths:
    - "CSI sanity test suite passes all snapshot test cases (CreateSnapshot, DeleteSnapshot, ListSnapshots) with zero failures"
    - "Sanity test config enables snapshot testing with correct parameters"
    - "Hardware validation TC-08 documents the copy-from snapshot approach (not Btrfs subvolume)"
    - "TC-08 verification steps reference /disk print (not /disk/btrfs/subvolume/print)"
    - "TC-08 expected RDS output shows type=file without nvme-tcp-export (not type=snapshot with read-only=yes)"
  artifacts:
    - path: "test/sanity/sanity_test.go"
      provides: "CSI sanity test with working snapshot parameters"
      contains: "TestSnapshotParameters"
    - path: "docs/HARDWARE_VALIDATION.md"
      provides: "Updated TC-08 with copy-from snapshot validation steps"
      contains: "copy-from"
  key_links:
    - from: "test/sanity/sanity_test.go"
      to: "test/mock/rds_server.go"
      via: "Mock server handles snapshot SSH commands from CSI driver"
      pattern: "mock.NewMockRDSServer"
    - from: "test/sanity/sanity_test.go"
      to: "pkg/driver/controller.go"
      via: "CSI gRPC calls CreateSnapshot/DeleteSnapshot/ListSnapshots"
      pattern: "sanity.Test"
    - from: "docs/HARDWARE_VALIDATION.md"
      to: "pkg/rds/commands.go"
      via: "SSH commands documented match actual driver implementation"
      pattern: "copy-from"
---

<objective>
Run CSI sanity test suite to verify snapshot operations pass end-to-end with the updated mock server, fix any failures, and update the hardware validation TC-08 to document the copy-from snapshot approach.

Purpose: The CSI sanity test suite is the canonical validation that the driver implements the CSI spec correctly. With the mock server updated (Plan 01), the sanity snapshot tests should now work with copy-from semantics. TC-08 in HARDWARE_VALIDATION.md still references the old Btrfs subvolume approach and needs updating.

Output: Passing CSI sanity tests (including snapshots); updated TC-08 hardware validation test case.
</objective>

<execution_context>
@/Users/whiskey/.claude/get-shit-done/workflows/execute-plan.md
@/Users/whiskey/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-snapshot-implementation-fix/29-01-SUMMARY.md
@.planning/phases/29-snapshot-implementation-fix/29-02-SUMMARY.md
@.planning/phases/30-snapshot-validation/30-01-SUMMARY.md
@test/sanity/sanity_test.go
@test/mock/rds_server.go
@docs/HARDWARE_VALIDATION.md
@pkg/driver/controller.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run CSI sanity snapshot tests and fix any failures</name>
  <files>test/sanity/sanity_test.go</files>
  <action>
Run the CSI sanity test suite with `go test ./test/sanity/ -v -timeout 120s` and analyze results.

**Expected behavior:** The sanity test already has `TestSnapshotParameters` configured (line 204). With the mock server now handling copy-from, snapshot sanity tests should pass. If they fail, diagnose and fix.

**Update sanity test config if needed:**
- Remove the outdated comment on line 205-207 about "Btrfs snapshots" and "btrfsFSLabel" — the snapshot flow no longer uses Btrfs labels
- Update comment to: `// Snapshot parameters - copy-from approach needs no special SC parameters`
- Ensure `TestSnapshotParameters` map is correct for the new approach (should be empty map `map[string]string{}` since copy-from snapshots don't need extra SC params)

**Common failure patterns to watch for and fix:**

1. **"bad command name /disk/btrfs/subvolume"** in mock server output: Means the driver is still sending old Btrfs commands. This should NOT happen after Phase 29 rewrote commands.go — if it does, check that pkg/rds/commands.go has the copy-from implementations.

2. **Snapshot not found after create**: Mock server's `/disk print detail where slot=snap-*` may not return output in the format parseSnapshotInfo() expects. Check that the mock's formatDiskDetail output matches what parseSnapshotInfo parses (slot="...", file-path="...", file-size=NNN).

3. **Idempotency failure**: CSI sanity calls CreateSnapshot twice with same name. The mock server's handleDiskAdd must return success (not "already exists" error) when a snapshot with the same slot already exists. Check that the copy-from path in handleDiskAdd checks `s.snapshots[slot]` for existing entry and returns success if it matches.

4. **ListSnapshots returns wrong count**: The sanity test may call ListSnapshots and expect specific entries. Ensure the mock's handleDiskPrintDetail with `slot~"snap-"` pattern returns all snapshot entries.

5. **DeleteSnapshot fails**: Ensure handleDiskRemove checks both s.volumes and s.snapshots maps.

**If the sanity test has a csi-sanity binary dependency**, check if it's installed:
```bash
which csi-sanity || go install github.com/kubernetes-csi/csi-test/v5/cmd/csi-sanity@latest
```
Note: The sanity test uses the Go library `github.com/kubernetes-csi/csi-test/v5/pkg/sanity` (in-process), not the binary. No external binary needed.

After fixing any issues, run the full sanity suite again to confirm all tests pass. Also run `go test ./pkg/... -count=1` to confirm no regressions in unit tests.
  </action>
  <verify>
`go test ./test/sanity/ -v -timeout 120s` passes with 0 failures.
`go test ./pkg/... -count=1` still passes (no regressions).
  </verify>
  <done>
CSI sanity test suite passes all test cases including CreateSnapshot, DeleteSnapshot, and ListSnapshots operations. No regressions in any package tests.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update TC-08 hardware validation for copy-from snapshot approach</name>
  <files>docs/HARDWARE_VALIDATION.md</files>
  <action>
Update the TC-08 section in docs/HARDWARE_VALIDATION.md to reflect the copy-from snapshot implementation from Phase 29. The current TC-08 references Btrfs subvolume commands and output formats that no longer match reality.

**Changes to TC-08 header and description:**
- Change "Validate Btrfs snapshot create/restore/delete via CSI driver" to "Validate volume snapshot create/restore/delete via CSI driver using copy-from CoW copies"

**Changes to Step 4 (Verify Snapshot on RDS via SSH):**
- Replace the SSH command: Instead of checking `/disk/btrfs/subvolume/print`, use `/disk print detail where slot~"snap-"`
- Update the expected output to show copy-from disk format:
```
slot="snap-<source-uuid>-at-<hash>" type="file" file-path="/storage-pool/metal-csi/snap-<source-uuid>-at-<hash>.img" file-size=5368709120 status="ready"
```
- Remove references to `type=snapshot`, `read-only=yes`, `snapshot-of=` — these are Btrfs subvolume concepts
- Add note: "Snapshot disks are standard file-backed disks created via copy-from. They have NO nvme-tcp-export (not network-exported). The absence of NVMe flags is what makes them immutable backups."
- Update the snapshot ID format description: explain that slot names use `snap-<source-uuid>-at-<deterministic-hash>` format

**Changes to Step 7 (Delete Snapshot verification):**
- Replace SSH verification command with `/disk print detail where slot~"snap-"` (was `/disk/btrfs/subvolume/print`)
- Note that DeleteSnapshot also removes the backing .img file (belt-and-suspenders cleanup)

**Changes to Success Criteria:**
- Replace "Snapshot visible on RDS with correct attributes (type=snapshot, read-only=yes)" with "Snapshot visible on RDS as file-backed disk with no NVMe export flags"
- Replace "Snapshot deletion removes from RDS" with "Snapshot deletion removes both disk entry and backing .img file from RDS"

**Changes to Troubleshooting:**
- Replace "Btrfs snapshot corruption or incorrect snapshot-of reference" with "copy-from failure or source volume not found"
- Replace "verify RDS Btrfs pool health" with "verify source volume exists and RDS has sufficient space for CoW copy"
- Remove reference to "VolumeSnapshotClass" Btrfs-specific notes
- Update "Data mismatch" troubleshooting to reference copy-from independent copy semantics

**Also update:** The Results Template table at the bottom — TC-08 description should say "Snapshot Operations (copy-from)" instead of just "Snapshot Operations"

**Do NOT change:** Any other test cases (TC-01 through TC-07), the Prerequisites section, the Performance Baselines section, or the Troubleshooting Decision Tree.
  </action>
  <verify>
Grep for "btrfs/subvolume" in docs/HARDWARE_VALIDATION.md — should return 0 matches.
Grep for "copy-from" in docs/HARDWARE_VALIDATION.md — should return at least 1 match.
Grep for "type=snapshot" in docs/HARDWARE_VALIDATION.md — should return 0 matches.
Grep for "read-only=yes" in docs/HARDWARE_VALIDATION.md — should return 0 matches (in TC-08 context).
  </verify>
  <done>
TC-08 documents the copy-from snapshot approach: SSH verification uses `/disk print detail`, expected output shows file-backed disk without NVMe export, troubleshooting references copy-from semantics. No Btrfs subvolume references remain.
  </done>
</task>

</tasks>

<verification>
1. `go test ./test/sanity/ -v -timeout 120s` passes with 0 failures (snapshot tests included)
2. `go test ./pkg/... -count=1` passes (no regressions)
3. `go test ./test/mock/... -count=1` passes (mock server tests from Plan 01 still pass)
4. `grep -c "btrfs/subvolume" docs/HARDWARE_VALIDATION.md` returns 0
5. `grep -c "copy-from" docs/HARDWARE_VALIDATION.md` returns > 0
6. TC-08 steps reference `/disk print detail` for verification (not Btrfs commands)
</verification>

<success_criteria>
- CSI sanity test suite passes 100% including all snapshot test cases
- No regressions in any existing unit test packages
- TC-08 hardware validation reflects the actual copy-from implementation
- No Btrfs subvolume references remain in TC-08
- Snapshot verification on RDS uses `/disk print detail where slot~"snap-"`
</success_criteria>

<output>
After completion, create `.planning/phases/30-snapshot-validation/30-02-SUMMARY.md`
</output>
