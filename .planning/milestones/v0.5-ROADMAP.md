# Milestone v0.5: KubeVirt Live Migration

**Status:** In Progress
**Phases:** 8-10
**Total Plans:** 3 (Phase 8) + 4 (Phase 9) + 5 (Phase 10, including 1 gap closure)

## Overview

This roadmap enables KubeVirt VM live migration with RDS CSI volumes. Three phases build from capability to safety to observability: adding ReadWriteMany block volume support with a 2-node attachment limit, implementing migration-specific safety controls that differentiate from RWO conflict detection, and exposing migration metrics and events for operator visibility. The driver will allow temporary dual-node attachment during migration while rejecting unsafe RWX filesystem volumes.

## Phases

### Phase 8: Core RWX Capability
**Goal**: KubeVirt VMs can live migrate using RWX block PVCs
**Depends on**: Phase 7 (Robustness and Observability from v0.3)
**Requirements**: RWX-01, RWX-02, RWX-03
**Plans**: 3 plans in 3 waves

**Success Criteria** (what must be TRUE):
1. User can create PVC with `accessModes: [ReadWriteMany]` and `volumeMode: Block` that is accepted by the driver
2. User receives a clear error when attempting to create PVC with `accessModes: [ReadWriteMany]` and `volumeMode: Filesystem`
3. Volume can be attached to exactly 2 nodes simultaneously (source and destination during migration)
4. ControllerGetCapabilities declares MULTI_NODE_MULTI_WRITER for block volumes only

Plans:
- [x] 08-01-PLAN.md — Add MULTI_NODE_MULTI_WRITER capability and RWX block-only validation
- [x] 08-02-PLAN.md — Modify AttachmentManager to allow 2-node attachment for RWX block volumes
- [x] 08-03-PLAN.md — Comprehensive unit tests

**Details:**
- Add `MULTI_NODE_MULTI_WRITER` to driver vcaps array in pkg/driver/driver.go
- Validate that RWX requests have `cap.GetBlock() != nil`, reject mount volumes
- Modify ControllerPublishVolume to allow 2-node attachment when access mode is RWX and volume mode is block
- Enforce strict 2-node limit (not unlimited multi-attach)

### Phase 9: Migration Safety
**Goal**: Migration dual-attachment is distinguishable from RWO conflicts with appropriate timeout and cleanup behavior
**Depends on**: Phase 8
**Requirements**: SAFETY-01, SAFETY-02, SAFETY-03, SAFETY-04
**Plans**: 4 plans in 3 waves

**Success Criteria** (what must be TRUE):
1. Migration timeout (5 min default, configurable via StorageClass) allows dual-attachment window without triggering conflict
2. Non-migration dual-attach attempts fail immediately with FAILED_PRECONDITION (no grace period applied)
3. AttachmentState tracks secondary attachment with migration timestamp for reconciler cleanup
4. NodeUnstageVolume verifies no open file descriptors before issuing NVMe disconnect

Plans:
- [x] 09-01-PLAN.md — Extend AttachmentState for migration tracking and configurable timeout
- [x] 09-02-PLAN.md — Separate migration timeout from RWO conflict detection logic
- [x] 09-03-PLAN.md — Device-in-use verification in NodeUnstageVolume
- [x] 09-04-PLAN.md — Comprehensive unit tests

**Details:**
- Extend AttachmentState struct with MigrationStartedAt timestamp and MigrationTimeout duration
- StorageClass parameter `migrationTimeoutSeconds` (default 300, range 30-3600)
- ParseMigrationTimeout validates and clamps timeout to safe range
- Migration detection: RWX block volume + 2-node attachment pattern
- Timed-out migrations reject new secondary attachments with clear error
- Non-migration RWO conflicts fail immediately (existing behavior preserved)
- CheckDeviceInUse via lsof (5s timeout) before NVMe disconnect
- Migration state cleared automatically when source node detaches

### Phase 10: Observability
**Goal**: Operators can monitor migrations and users understand safe RWX usage
**Depends on**: Phase 9
**Requirements**: OBS-01, OBS-02, OBS-03
**Plans**: 5 plans in 2 waves (including 1 gap closure)

**Success Criteria** (what must be TRUE):
1. Prometheus metrics expose `migrations_total`, `migration_duration_seconds`, `active_migrations` gauge
2. Kubernetes events posted to PVC: MigrationStarted, MigrationCompleted, MigrationFailed
3. User documentation clearly explains RWX is safe only for KubeVirt live migration (not general RWX workloads)

Plans:
- [x] 10-01-PLAN.md — Prometheus migration metrics (3 metrics, recording methods)
- [x] 10-02-PLAN.md — Kubernetes migration events on PVC (3 event types)
- [x] 10-03-PLAN.md — Wire metrics/events into attachment manager and controller
- [x] 10-04-PLAN.md — User documentation for RWX safety (docs/kubevirt-migration.md)
- [ ] 10-05-PLAN.md — Gap closure: Wire PostMigrationCompleted in ControllerUnpublishVolume

**Details:**
- Metrics with `rds_csi_migration_` prefix
- `migrations_total` counter with labels: result (success/failed/timeout)
- `migration_duration_seconds` histogram
- `active_migrations` gauge (current in-flight migrations)
- Events: MigrationStarted (when 2nd node attaches), MigrationCompleted (when 1st node detaches), MigrationFailed (on timeout or error)
- Documentation in docs/kubevirt-migration.md with explicit warnings about data corruption risk outside KubeVirt

---

## Milestone Summary

**Decimal Phases:** None (no urgent insertions yet)

**Key Decisions:**
- ROADMAP-4: RWX block-only, reject RWX filesystem (prevents data corruption)
- ROADMAP-5: 2-node limit during migration (sufficient for KubeVirt, prevents misuse)
- ROADMAP-6: Trust QEMU for I/O coordination (driver permits dual-attach, doesn't coordinate)

**Issues Targeted:**
- VMs show "Live Migration: false" due to missing RWX support
- KubeVirt live migration fails with RDS CSI volumes
- Need dual-node attachment during migration handoff

**Issues Deferred:**
- Cluster filesystem support (GFS2/OCFS2) for true RWX filesystem volumes
- RDS-level namespace reservations/fencing for split-brain protection
- KubeVirt API client integration for richer migration awareness

**Technical Debt Incurred:**
- TBD (will be tracked during execution)

---

*For previous milestones, see .planning/milestones/v0.3-ROADMAP.md*
*Milestone started: 2026-02-03*
